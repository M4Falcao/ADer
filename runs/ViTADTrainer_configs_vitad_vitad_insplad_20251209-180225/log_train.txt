2025-12-09 18:02:25,809 - ==> Logging on master GPU: 0
2025-12-09 18:02:25,809 - ==> Running Trainer: ViTADTrainer
2025-12-09 18:02:25,809 - ==> Using GPU: [0] for Training
2025-12-09 18:02:25,809 - ==> Building model
2025-12-09 18:02:25,985 - Loading pretrained weights from Hugging Face hub (timm/vit_small_patch16_224.dino)
2025-12-09 18:02:26,457 - HTTP Request: HEAD https://huggingface.co/timm/vit_small_patch16_224.dino/resolve/main/model.safetensors "HTTP/1.1 302 Found"
2025-12-09 18:02:26,459 - [timm/vit_small_patch16_224.dino] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-09 18:02:26,464 - Resized position embedding: (14, 14) to (16, 16).
2025-12-09 18:02:27,307 - 
------------------------------------ ViTAD ------------------------------------
| module                            | #parameters or shape   | #flops       |
|:----------------------------------|:-----------------------|:-------------|
| model                             | 38.586M                | 9.668G       |
|  net_t                            |  21.689M               |  5.544G      |
|   net_t.cls_token                 |   (1, 1, 384)          |              |
|   net_t.pos_embed                 |   (1, 257, 384)        |              |
|   net_t.patch_embed.proj          |   0.295M               |   75.497M    |
|    net_t.patch_embed.proj.weight  |    (384, 3, 16, 16)    |              |
|    net_t.patch_embed.proj.bias    |    (384,)              |              |
|   net_t.blocks                    |   21.294M              |   5.469G     |
|    net_t.blocks.0                 |    1.774M              |    0.456G    |
|     net_t.blocks.0.norm1          |     0.768K             |     0.493M   |
|      net_t.blocks.0.norm1.weight  |      (384,)            |              |
|      net_t.blocks.0.norm1.bias    |      (384,)            |              |
|     net_t.blocks.0.attn           |     0.591M             |     0.152G   |
|      net_t.blocks.0.attn.qkv      |      0.444M            |      0.114G  |
|      net_t.blocks.0.attn.proj     |      0.148M            |      37.896M |
|     net_t.blocks.0.norm2          |     0.768K             |     0.493M   |
|      net_t.blocks.0.norm2.weight  |      (384,)            |              |
|      net_t.blocks.0.norm2.bias    |      (384,)            |              |
|     net_t.blocks.0.mlp            |     1.182M             |     0.303G   |
|      net_t.blocks.0.mlp.fc1       |      0.591M            |      0.152G  |
|      net_t.blocks.0.mlp.fc2       |      0.59M             |      0.152G  |
|    net_t.blocks.1                 |    1.774M              |    0.456G    |
|     net_t.blocks.1.norm1          |     0.768K             |     0.493M   |
|      net_t.blocks.1.norm1.weight  |      (384,)            |              |
|      net_t.blocks.1.norm1.bias    |      (384,)            |              |
|     net_t.blocks.1.attn           |     0.591M             |     0.152G   |
|      net_t.blocks.1.attn.qkv      |      0.444M            |      0.114G  |
|      net_t.blocks.1.attn.proj     |      0.148M            |      37.896M |
|     net_t.blocks.1.norm2          |     0.768K             |     0.493M   |
|      net_t.blocks.1.norm2.weight  |      (384,)            |              |
|      net_t.blocks.1.norm2.bias    |      (384,)            |              |
|     net_t.blocks.1.mlp            |     1.182M             |     0.303G   |
|      net_t.blocks.1.mlp.fc1       |      0.591M            |      0.152G  |
|      net_t.blocks.1.mlp.fc2       |      0.59M             |      0.152G  |
|    net_t.blocks.2                 |    1.774M              |    0.456G    |
|     net_t.blocks.2.norm1          |     0.768K             |     0.493M   |
|      net_t.blocks.2.norm1.weight  |      (384,)            |              |
|      net_t.blocks.2.norm1.bias    |      (384,)            |              |
|     net_t.blocks.2.attn           |     0.591M             |     0.152G   |
|      net_t.blocks.2.attn.qkv      |      0.444M            |      0.114G  |
|      net_t.blocks.2.attn.proj     |      0.148M            |      37.896M |
|     net_t.blocks.2.norm2          |     0.768K             |     0.493M   |
|      net_t.blocks.2.norm2.weight  |      (384,)            |              |
|      net_t.blocks.2.norm2.bias    |      (384,)            |              |
|     net_t.blocks.2.mlp            |     1.182M             |     0.303G   |
|      net_t.blocks.2.mlp.fc1       |      0.591M            |      0.152G  |
|      net_t.blocks.2.mlp.fc2       |      0.59M             |      0.152G  |
|    net_t.blocks.3                 |    1.774M              |    0.456G    |
|     net_t.blocks.3.norm1          |     0.768K             |     0.493M   |
|      net_t.blocks.3.norm1.weight  |      (384,)            |              |
|      net_t.blocks.3.norm1.bias    |      (384,)            |              |
|     net_t.blocks.3.attn           |     0.591M             |     0.152G   |
|      net_t.blocks.3.attn.qkv      |      0.444M            |      0.114G  |
|      net_t.blocks.3.attn.proj     |      0.148M            |      37.896M |
|     net_t.blocks.3.norm2          |     0.768K             |     0.493M   |
|      net_t.blocks.3.norm2.weight  |      (384,)            |              |
|      net_t.blocks.3.norm2.bias    |      (384,)            |              |
|     net_t.blocks.3.mlp            |     1.182M             |     0.303G   |
|      net_t.blocks.3.mlp.fc1       |      0.591M            |      0.152G  |
|      net_t.blocks.3.mlp.fc2       |      0.59M             |      0.152G  |
|    net_t.blocks.4                 |    1.774M              |    0.456G    |
|     net_t.blocks.4.norm1          |     0.768K             |     0.493M   |
|      net_t.blocks.4.norm1.weight  |      (384,)            |              |
|      net_t.blocks.4.norm1.bias    |      (384,)            |              |
|     net_t.blocks.4.attn           |     0.591M             |     0.152G   |
|      net_t.blocks.4.attn.qkv      |      0.444M            |      0.114G  |
|      net_t.blocks.4.attn.proj     |      0.148M            |      37.896M |
|     net_t.blocks.4.norm2          |     0.768K             |     0.493M   |
|      net_t.blocks.4.norm2.weight  |      (384,)            |              |
|      net_t.blocks.4.norm2.bias    |      (384,)            |              |
|     net_t.blocks.4.mlp            |     1.182M             |     0.303G   |
|      net_t.blocks.4.mlp.fc1       |      0.591M            |      0.152G  |
|      net_t.blocks.4.mlp.fc2       |      0.59M             |      0.152G  |
|    net_t.blocks.5                 |    1.774M              |    0.456G    |
|     net_t.blocks.5.norm1          |     0.768K             |     0.493M   |
|      net_t.blocks.5.norm1.weight  |      (384,)            |              |
|      net_t.blocks.5.norm1.bias    |      (384,)            |              |
|     net_t.blocks.5.attn           |     0.591M             |     0.152G   |
|      net_t.blocks.5.attn.qkv      |      0.444M            |      0.114G  |
|      net_t.blocks.5.attn.proj     |      0.148M            |      37.896M |
|     net_t.blocks.5.norm2          |     0.768K             |     0.493M   |
|      net_t.blocks.5.norm2.weight  |      (384,)            |              |
|      net_t.blocks.5.norm2.bias    |      (384,)            |              |
|     net_t.blocks.5.mlp            |     1.182M             |     0.303G   |
|      net_t.blocks.5.mlp.fc1       |      0.591M            |      0.152G  |
|      net_t.blocks.5.mlp.fc2       |      0.59M             |      0.152G  |
|    net_t.blocks.6                 |    1.774M              |    0.456G    |
|     net_t.blocks.6.norm1          |     0.768K             |     0.493M   |
|      net_t.blocks.6.norm1.weight  |      (384,)            |              |
|      net_t.blocks.6.norm1.bias    |      (384,)            |              |
|     net_t.blocks.6.attn           |     0.591M             |     0.152G   |
|      net_t.blocks.6.attn.qkv      |      0.444M            |      0.114G  |
|      net_t.blocks.6.attn.proj     |      0.148M            |      37.896M |
|     net_t.blocks.6.norm2          |     0.768K             |     0.493M   |
|      net_t.blocks.6.norm2.weight  |      (384,)            |              |
|      net_t.blocks.6.norm2.bias    |      (384,)            |              |
|     net_t.blocks.6.mlp            |     1.182M             |     0.303G   |
|      net_t.blocks.6.mlp.fc1       |      0.591M            |      0.152G  |
|      net_t.blocks.6.mlp.fc2       |      0.59M             |      0.152G  |
|    net_t.blocks.7                 |    1.774M              |    0.456G    |
|     net_t.blocks.7.norm1          |     0.768K             |     0.493M   |
|      net_t.blocks.7.norm1.weight  |      (384,)            |              |
|      net_t.blocks.7.norm1.bias    |      (384,)            |              |
|     net_t.blocks.7.attn           |     0.591M             |     0.152G   |
|      net_t.blocks.7.attn.qkv      |      0.444M            |      0.114G  |
|      net_t.blocks.7.attn.proj     |      0.148M            |      37.896M |
|     net_t.blocks.7.norm2          |     0.768K             |     0.493M   |
|      net_t.blocks.7.norm2.weight  |      (384,)            |              |
|      net_t.blocks.7.norm2.bias    |      (384,)            |              |
|     net_t.blocks.7.mlp            |     1.182M             |     0.303G   |
|      net_t.blocks.7.mlp.fc1       |      0.591M            |      0.152G  |
|      net_t.blocks.7.mlp.fc2       |      0.59M             |      0.152G  |
|    net_t.blocks.8                 |    1.774M              |    0.456G    |
|     net_t.blocks.8.norm1          |     0.768K             |     0.493M   |
|      net_t.blocks.8.norm1.weight  |      (384,)            |              |
|      net_t.blocks.8.norm1.bias    |      (384,)            |              |
|     net_t.blocks.8.attn           |     0.591M             |     0.152G   |
|      net_t.blocks.8.attn.qkv      |      0.444M            |      0.114G  |
|      net_t.blocks.8.attn.proj     |      0.148M            |      37.896M |
|     net_t.blocks.8.norm2          |     0.768K             |     0.493M   |
|      net_t.blocks.8.norm2.weight  |      (384,)            |              |
|      net_t.blocks.8.norm2.bias    |      (384,)            |              |
|     net_t.blocks.8.mlp            |     1.182M             |     0.303G   |
|      net_t.blocks.8.mlp.fc1       |      0.591M            |      0.152G  |
|      net_t.blocks.8.mlp.fc2       |      0.59M             |      0.152G  |
|    net_t.blocks.9                 |    1.774M              |    0.456G    |
|     net_t.blocks.9.norm1          |     0.768K             |     0.493M   |
|      net_t.blocks.9.norm1.weight  |      (384,)            |              |
|      net_t.blocks.9.norm1.bias    |      (384,)            |              |
|     net_t.blocks.9.attn           |     0.591M             |     0.152G   |
|      net_t.blocks.9.attn.qkv      |      0.444M            |      0.114G  |
|      net_t.blocks.9.attn.proj     |      0.148M            |      37.896M |
|     net_t.blocks.9.norm2          |     0.768K             |     0.493M   |
|      net_t.blocks.9.norm2.weight  |      (384,)            |              |
|      net_t.blocks.9.norm2.bias    |      (384,)            |              |
|     net_t.blocks.9.mlp            |     1.182M             |     0.303G   |
|      net_t.blocks.9.mlp.fc1       |      0.591M            |      0.152G  |
|      net_t.blocks.9.mlp.fc2       |      0.59M             |      0.152G  |
|    net_t.blocks.10                |    1.774M              |    0.456G    |
|     net_t.blocks.10.norm1         |     0.768K             |     0.493M   |
|      net_t.blocks.10.norm1.weight |      (384,)            |              |
|      net_t.blocks.10.norm1.bias   |      (384,)            |              |
|     net_t.blocks.10.attn          |     0.591M             |     0.152G   |
|      net_t.blocks.10.attn.qkv     |      0.444M            |      0.114G  |
|      net_t.blocks.10.attn.proj    |      0.148M            |      37.896M |
|     net_t.blocks.10.norm2         |     0.768K             |     0.493M   |
|      net_t.blocks.10.norm2.weight |      (384,)            |              |
|      net_t.blocks.10.norm2.bias   |      (384,)            |              |
|     net_t.blocks.10.mlp           |     1.182M             |     0.303G   |
|      net_t.blocks.10.mlp.fc1      |      0.591M            |      0.152G  |
|      net_t.blocks.10.mlp.fc2      |      0.59M             |      0.152G  |
|    net_t.blocks.11                |    1.774M              |    0.456G    |
|     net_t.blocks.11.norm1         |     0.768K             |     0.493M   |
|      net_t.blocks.11.norm1.weight |      (384,)            |              |
|      net_t.blocks.11.norm1.bias   |      (384,)            |              |
|     net_t.blocks.11.attn          |     0.591M             |     0.152G   |
|      net_t.blocks.11.attn.qkv     |      0.444M            |      0.114G  |
|      net_t.blocks.11.attn.proj    |      0.148M            |      37.896M |
|     net_t.blocks.11.norm2         |     0.768K             |     0.493M   |
|      net_t.blocks.11.norm2.weight |      (384,)            |              |
|      net_t.blocks.11.norm2.bias   |      (384,)            |              |
|     net_t.blocks.11.mlp           |     1.182M             |     0.303G   |
|      net_t.blocks.11.mlp.fc1      |      0.591M            |      0.152G  |
|      net_t.blocks.11.mlp.fc2      |      0.59M             |      0.152G  |
|   net_t.norm                      |   0.768K               |              |
|    net_t.norm.weight              |    (384,)              |              |
|    net_t.norm.bias                |    (384,)              |              |
|  net_fusion.fc                    |  0.148M                |  37.749M     |
|   net_fusion.fc.weight            |   (384, 384)           |              |
|   net_fusion.fc.bias              |   (384,)               |              |
|  net_s                            |  16.75M                |  4.086G      |
|   net_s.cls_token                 |   (1, 1, 384)          |              |
|   net_s.pos_embed                 |   (1, 256, 384)        |              |
|   net_s.patch_embed.proj          |   0.295M               |              |
|    net_s.patch_embed.proj.weight  |    (384, 3, 16, 16)    |              |
|    net_s.patch_embed.proj.bias    |    (384,)              |              |
|   net_s.blocks                    |   15.97M               |   4.086G     |
|    net_s.blocks.0                 |    1.774M              |    0.454G    |
|     net_s.blocks.0.norm1          |     0.768K             |     0.492M   |
|      net_s.blocks.0.norm1.weight  |      (384,)            |              |
|      net_s.blocks.0.norm1.bias    |      (384,)            |              |
|     net_s.blocks.0.attn           |     0.591M             |     0.151G   |
|      net_s.blocks.0.attn.qkv      |      0.444M            |      0.113G  |
|      net_s.blocks.0.attn.proj     |      0.148M            |      37.749M |
|     net_s.blocks.0.norm2          |     0.768K             |     0.492M   |
|      net_s.blocks.0.norm2.weight  |      (384,)            |              |
|      net_s.blocks.0.norm2.bias    |      (384,)            |              |
|     net_s.blocks.0.mlp            |     1.182M             |     0.302G   |
|      net_s.blocks.0.mlp.fc1       |      0.591M            |      0.151G  |
|      net_s.blocks.0.mlp.fc2       |      0.59M             |      0.151G  |
|    net_s.blocks.1                 |    1.774M              |    0.454G    |
|     net_s.blocks.1.norm1          |     0.768K             |     0.492M   |
|      net_s.blocks.1.norm1.weight  |      (384,)            |              |
|      net_s.blocks.1.norm1.bias    |      (384,)            |              |
|     net_s.blocks.1.attn           |     0.591M             |     0.151G   |
|      net_s.blocks.1.attn.qkv      |      0.444M            |      0.113G  |
|      net_s.blocks.1.attn.proj     |      0.148M            |      37.749M |
|     net_s.blocks.1.norm2          |     0.768K             |     0.492M   |
|      net_s.blocks.1.norm2.weight  |      (384,)            |              |
|      net_s.blocks.1.norm2.bias    |      (384,)            |              |
|     net_s.blocks.1.mlp            |     1.182M             |     0.302G   |
|      net_s.blocks.1.mlp.fc1       |      0.591M            |      0.151G  |
|      net_s.blocks.1.mlp.fc2       |      0.59M             |      0.151G  |
|    net_s.blocks.2                 |    1.774M              |    0.454G    |
|     net_s.blocks.2.norm1          |     0.768K             |     0.492M   |
|      net_s.blocks.2.norm1.weight  |      (384,)            |              |
|      net_s.blocks.2.norm1.bias    |      (384,)            |              |
|     net_s.blocks.2.attn           |     0.591M             |     0.151G   |
|      net_s.blocks.2.attn.qkv      |      0.444M            |      0.113G  |
|      net_s.blocks.2.attn.proj     |      0.148M            |      37.749M |
|     net_s.blocks.2.norm2          |     0.768K             |     0.492M   |
|      net_s.blocks.2.norm2.weight  |      (384,)            |              |
|      net_s.blocks.2.norm2.bias    |      (384,)            |              |
|     net_s.blocks.2.mlp            |     1.182M             |     0.302G   |
|      net_s.blocks.2.mlp.fc1       |      0.591M            |      0.151G  |
|      net_s.blocks.2.mlp.fc2       |      0.59M             |      0.151G  |
|    net_s.blocks.3                 |    1.774M              |    0.454G    |
|     net_s.blocks.3.norm1          |     0.768K             |     0.492M   |
|      net_s.blocks.3.norm1.weight  |      (384,)            |              |
|      net_s.blocks.3.norm1.bias    |      (384,)            |              |
|     net_s.blocks.3.attn           |     0.591M             |     0.151G   |
|      net_s.blocks.3.attn.qkv      |      0.444M            |      0.113G  |
|      net_s.blocks.3.attn.proj     |      0.148M            |      37.749M |
|     net_s.blocks.3.norm2          |     0.768K             |     0.492M   |
|      net_s.blocks.3.norm2.weight  |      (384,)            |              |
|      net_s.blocks.3.norm2.bias    |      (384,)            |              |
|     net_s.blocks.3.mlp            |     1.182M             |     0.302G   |
|      net_s.blocks.3.mlp.fc1       |      0.591M            |      0.151G  |
|      net_s.blocks.3.mlp.fc2       |      0.59M             |      0.151G  |
|    net_s.blocks.4                 |    1.774M              |    0.454G    |
|     net_s.blocks.4.norm1          |     0.768K             |     0.492M   |
|      net_s.blocks.4.norm1.weight  |      (384,)            |              |
|      net_s.blocks.4.norm1.bias    |      (384,)            |              |
|     net_s.blocks.4.attn           |     0.591M             |     0.151G   |
|      net_s.blocks.4.attn.qkv      |      0.444M            |      0.113G  |
|      net_s.blocks.4.attn.proj     |      0.148M            |      37.749M |
|     net_s.blocks.4.norm2          |     0.768K             |     0.492M   |
|      net_s.blocks.4.norm2.weight  |      (384,)            |              |
|      net_s.blocks.4.norm2.bias    |      (384,)            |              |
|     net_s.blocks.4.mlp            |     1.182M             |     0.302G   |
|      net_s.blocks.4.mlp.fc1       |      0.591M            |      0.151G  |
|      net_s.blocks.4.mlp.fc2       |      0.59M             |      0.151G  |
|    net_s.blocks.5                 |    1.774M              |    0.454G    |
|     net_s.blocks.5.norm1          |     0.768K             |     0.492M   |
|      net_s.blocks.5.norm1.weight  |      (384,)            |              |
|      net_s.blocks.5.norm1.bias    |      (384,)            |              |
|     net_s.blocks.5.attn           |     0.591M             |     0.151G   |
|      net_s.blocks.5.attn.qkv      |      0.444M            |      0.113G  |
|      net_s.blocks.5.attn.proj     |      0.148M            |      37.749M |
|     net_s.blocks.5.norm2          |     0.768K             |     0.492M   |
|      net_s.blocks.5.norm2.weight  |      (384,)            |              |
|      net_s.blocks.5.norm2.bias    |      (384,)            |              |
|     net_s.blocks.5.mlp            |     1.182M             |     0.302G   |
|      net_s.blocks.5.mlp.fc1       |      0.591M            |      0.151G  |
|      net_s.blocks.5.mlp.fc2       |      0.59M             |      0.151G  |
|    net_s.blocks.6                 |    1.774M              |    0.454G    |
|     net_s.blocks.6.norm1          |     0.768K             |     0.492M   |
|      net_s.blocks.6.norm1.weight  |      (384,)            |              |
|      net_s.blocks.6.norm1.bias    |      (384,)            |              |
|     net_s.blocks.6.attn           |     0.591M             |     0.151G   |
|      net_s.blocks.6.attn.qkv      |      0.444M            |      0.113G  |
|      net_s.blocks.6.attn.proj     |      0.148M            |      37.749M |
|     net_s.blocks.6.norm2          |     0.768K             |     0.492M   |
|      net_s.blocks.6.norm2.weight  |      (384,)            |              |
|      net_s.blocks.6.norm2.bias    |      (384,)            |              |
|     net_s.blocks.6.mlp            |     1.182M             |     0.302G   |
|      net_s.blocks.6.mlp.fc1       |      0.591M            |      0.151G  |
|      net_s.blocks.6.mlp.fc2       |      0.59M             |      0.151G  |
|    net_s.blocks.7                 |    1.774M              |    0.454G    |
|     net_s.blocks.7.norm1          |     0.768K             |     0.492M   |
|      net_s.blocks.7.norm1.weight  |      (384,)            |              |
|      net_s.blocks.7.norm1.bias    |      (384,)            |              |
|     net_s.blocks.7.attn           |     0.591M             |     0.151G   |
|      net_s.blocks.7.attn.qkv      |      0.444M            |      0.113G  |
|      net_s.blocks.7.attn.proj     |      0.148M            |      37.749M |
|     net_s.blocks.7.norm2          |     0.768K             |     0.492M   |
|      net_s.blocks.7.norm2.weight  |      (384,)            |              |
|      net_s.blocks.7.norm2.bias    |      (384,)            |              |
|     net_s.blocks.7.mlp            |     1.182M             |     0.302G   |
|      net_s.blocks.7.mlp.fc1       |      0.591M            |      0.151G  |
|      net_s.blocks.7.mlp.fc2       |      0.59M             |      0.151G  |
|    net_s.blocks.8                 |    1.774M              |    0.454G    |
|     net_s.blocks.8.norm1          |     0.768K             |     0.492M   |
|      net_s.blocks.8.norm1.weight  |      (384,)            |              |
|      net_s.blocks.8.norm1.bias    |      (384,)            |              |
|     net_s.blocks.8.attn           |     0.591M             |     0.151G   |
|      net_s.blocks.8.attn.qkv      |      0.444M            |      0.113G  |
|      net_s.blocks.8.attn.proj     |      0.148M            |      37.749M |
|     net_s.blocks.8.norm2          |     0.768K             |     0.492M   |
|      net_s.blocks.8.norm2.weight  |      (384,)            |              |
|      net_s.blocks.8.norm2.bias    |      (384,)            |              |
|     net_s.blocks.8.mlp            |     1.182M             |     0.302G   |
|      net_s.blocks.8.mlp.fc1       |      0.591M            |      0.151G  |
|      net_s.blocks.8.mlp.fc2       |      0.59M             |      0.151G  |
|   net_s.norm                      |   0.768K               |              |
|    net_s.norm.weight              |    (384,)              |              |
|    net_s.norm.bias                |    (384,)              |              |
|   net_s.head                      |   0.385M               |              |
|    net_s.head.weight              |    (1000, 384)         |              |
|    net_s.head.bias                |    (1000,)             |              |
-------------------------------------------------------------------------------
2025-12-09 18:02:27,309 - ==> Creating optimizer
2025-12-09 18:02:27,310 - ==> Loading dataset: DefaultAD
2025-12-09 18:02:27,365 - ==> ********** cfg ********** 
fvcore_is                            : True                                
fvcore_b                             : 1                                   
fvcore_c                             : 3                                   
epoch_full                           : 100                                 
metrics                              : ['mAUROC_sp_max', 'mAP_sp_max', 'mF1_max_sp_max', 'mAUPRO_px', 'mAUROC_px', 'mAP_px', 'mF1_max_px', 'mF1_px_0.2_0.8_0.1', 'mAcc_px_0.2_0.8_0.1', 'mIoU_px_0.2_0.8_0.1', 'mIoU_max_px']
use_adeval                           : True                                
evaluator.kwargs                     : {'metrics': ['mAUROC_sp_max', 'mAP_sp_max', 'mF1_max_sp_max', 'mAUPRO_px', 'mAUROC_px', 'mAP_px', 'mF1_max_px', 'mF1_px_0.2_0.8_0.1', 'mAcc_px_0.2_0.8_0.1', 'mIoU_px_0.2_0.8_0.1', 'mIoU_max_px'], 'pooling_ks': [16, 16], 'max_step_aupro': 100}
vis                                  : False                               
vis_dir                              : None                                
optim.lr                             : 0.0001                              
optim.kwargs                         : {'name': 'adamw', 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0001, 'amsgrad': False}
trainer.name                         : ViTADTrainer                        
trainer.checkpoint                   : runs                                
trainer.logdir_sub                   :                                     
trainer.resume_dir                   :                                     
trainer.cuda_deterministic           : False                               
trainer.epoch_full                   : 100                                 
trainer.scheduler_kwargs             : {'name': 'step', 'lr_noise': None, 'noise_pct': 0.67, 'noise_std': 1.0, 'noise_seed': 42, 'lr_min': 1e-06, 'warmup_lr': 1.0000000000000001e-07, 'warmup_iters': -1, 'cooldown_iters': 0, 'warmup_epochs': 0, 'cooldown_epochs': 0, 'use_iters': True, 'patience_iters': 0, 'patience_epochs': 0, 'decay_iters': 0, 'decay_epochs': 80, 'cycle_decay': 0.1, 'decay_rate': 0.1}
trainer.mixup_kwargs                 : {'mixup_alpha': 0.8, 'cutmix_alpha': 1.0, 'cutmix_minmax': None, 'prob': 0.0, 'switch_prob': 0.5, 'mode': 'batch', 'correct_lam': True, 'label_smoothing': 0.1}
trainer.test_start_epoch             : 100                                 
trainer.test_per_epoch               : 10                                  
trainer.find_unused_parameters       : False                               
trainer.sync_BN                      : apex                                
trainer.dist_BN                      :                                     
trainer.scaler                       : none                                
trainer.data.batch_size              : 8                                   
trainer.data.batch_size_per_gpu      : 8                                   
trainer.data.batch_size_test         : 8                                   
trainer.data.batch_size_per_gpu_test : 8                                   
trainer.data.num_workers_per_gpu     : 4                                   
trainer.data.drop_last               : True                                
trainer.data.pin_memory              : True                                
trainer.data.persistent_workers      : False                               
trainer.data.num_workers             : 4                                   
trainer.iter                         : 0                                   
trainer.epoch                        : 0                                   
trainer.iter_full                    : 97600                               
trainer.metric_recorder              : {'mAUROC_sp_max_glass-insulator': [], 'mAP_sp_max_glass-insulator': [], 'mF1_max_sp_max_glass-insulator': [], 'mAUPRO_px_glass-insulator': [], 'mAUROC_px_glass-insulator': [], 'mAP_px_glass-insulator': [], 'mF1_max_px_glass-insulator': [], 'mF1_px_0.2_0.8_0.1_glass-insulator': [], 'mAcc_px_0.2_0.8_0.1_glass-insulator': [], 'mIoU_px_0.2_0.8_0.1_glass-insulator': [], 'mIoU_max_px_glass-insulator': [], 'mAUROC_sp_max_lightning-rod-suspension': [], 'mAP_sp_max_lightning-rod-suspension': [], 'mF1_max_sp_max_lightning-rod-suspension': [], 'mAUPRO_px_lightning-rod-suspension': [], 'mAUROC_px_lightning-rod-suspension': [], 'mAP_px_lightning-rod-suspension': [], 'mF1_max_px_lightning-rod-suspension': [], 'mF1_px_0.2_0.8_0.1_lightning-rod-suspension': [], 'mAcc_px_0.2_0.8_0.1_lightning-rod-suspension': [], 'mIoU_px_0.2_0.8_0.1_lightning-rod-suspension': [], 'mIoU_max_px_lightning-rod-suspension': [], 'mAUROC_sp_max_polymer-insulator-upper-shackle': [], 'mAP_sp_max_polymer-insulator-upper-shackle': [], 'mF1_max_sp_max_polymer-insulator-upper-shackle': [], 'mAUPRO_px_polymer-insulator-upper-shackle': [], 'mAUROC_px_polymer-insulator-upper-shackle': [], 'mAP_px_polymer-insulator-upper-shackle': [], 'mF1_max_px_polymer-insulator-upper-shackle': [], 'mF1_px_0.2_0.8_0.1_polymer-insulator-upper-shackle': [], 'mAcc_px_0.2_0.8_0.1_polymer-insulator-upper-shackle': [], 'mIoU_px_0.2_0.8_0.1_polymer-insulator-upper-shackle': [], 'mIoU_max_px_polymer-insulator-upper-shackle': [], 'mAUROC_sp_max_vari-grip': [], 'mAP_sp_max_vari-grip': [], 'mF1_max_sp_max_vari-grip': [], 'mAUPRO_px_vari-grip': [], 'mAUROC_px_vari-grip': [], 'mAP_px_vari-grip': [], 'mF1_max_px_vari-grip': [], 'mF1_px_0.2_0.8_0.1_vari-grip': [], 'mAcc_px_0.2_0.8_0.1_vari-grip': [], 'mIoU_px_0.2_0.8_0.1_vari-grip': [], 'mIoU_max_px_vari-grip': [], 'mAUROC_sp_max_yoke-suspension': [], 'mAUROC_sp_max_Avg': [], 'mAP_sp_max_yoke-suspension': [], 'mAP_sp_max_Avg': [], 'mF1_max_sp_max_yoke-suspension': [], 'mF1_max_sp_max_Avg': [], 'mAUPRO_px_yoke-suspension': [], 'mAUPRO_px_Avg': [], 'mAUROC_px_yoke-suspension': [], 'mAUROC_px_Avg': [], 'mAP_px_yoke-suspension': [], 'mAP_px_Avg': [], 'mF1_max_px_yoke-suspension': [], 'mF1_max_px_Avg': [], 'mF1_px_0.2_0.8_0.1_yoke-suspension': [], 'mF1_px_0.2_0.8_0.1_Avg': [], 'mAcc_px_0.2_0.8_0.1_yoke-suspension': [], 'mAcc_px_0.2_0.8_0.1_Avg': [], 'mIoU_px_0.2_0.8_0.1_yoke-suspension': [], 'mIoU_px_0.2_0.8_0.1_Avg': [], 'mIoU_max_px_yoke-suspension': [], 'mIoU_max_px_Avg': []}
loss.loss_terms                      : [{'type': 'CosLoss', 'name': 'cos', 'avg': False, 'lam': 1.0}]
loss.clip_grad                       : 5.0                                 
loss.create_graph                    : False                               
loss.retain_graph                    : False                               
adv                                  : False                               
logging.log_terms_train              : [{'name': 'batch_t', 'fmt': ':>5.3f', 'add_name': 'avg'}, {'name': 'data_t', 'fmt': ':>5.3f'}, {'name': 'optim_t', 'fmt': ':>5.3f'}, {'name': 'lr', 'fmt': ':>7.6f'}, {'name': 'cos', 'suffixes': [''], 'fmt': ':>5.3f', 'add_name': 'avg'}]
logging.log_terms_test               : [{'name': 'batch_t', 'fmt': ':>5.3f', 'add_name': 'avg'}, {'name': 'cos', 'suffixes': [''], 'fmt': ':>5.3f', 'add_name': 'avg'}]
logging.train_reset_log_per          : 50                                  
logging.train_log_per                : 50                                  
logging.test_log_per                 : 50                                  
data.sampler                         : naive                               
data.loader_type                     : pil                                 
data.loader_type_target              : pil_L                               
data.type                            : DefaultAD                           
data.root                            : data/insplad-seg                    
data.meta                            : meta.json                           
data.cls_names                       : []                                  
data.train_transforms                : [{'type': 'Resize', 'size': (256, 256), 'interpolation': <InterpolationMode.BILINEAR: 'bilinear'>}, {'type': 'CenterCrop', 'size': (256, 256)}, {'type': 'ToTensor'}, {'type': 'Normalize', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'inplace': True}]
data.test_transforms                 : [{'type': 'Resize', 'size': (256, 256), 'interpolation': <InterpolationMode.BILINEAR: 'bilinear'>}, {'type': 'CenterCrop', 'size': (256, 256)}, {'type': 'ToTensor'}, {'type': 'Normalize', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'inplace': True}]
data.target_transforms               : [{'type': 'Resize', 'size': (256, 256), 'interpolation': <InterpolationMode.BILINEAR: 'bilinear'>}, {'type': 'CenterCrop', 'size': (256, 256)}, {'type': 'ToTensor'}]
data.train_size                      : 976                                 
data.test_size                       : 321                                 
data.train_length                    : 7812                                
data.test_length                     : 2565                                
model_t.name                         : vit_small_patch16_224_dino          
model_t.kwargs                       : {'pretrained': True, 'checkpoint_path': '', 'pretrained_strict': False, 'strict': True, 'img_size': 256, 'teachers': [3, 6, 9], 'neck': [12]}
model_f.name                         : fusion                              
model_f.kwargs                       : {'pretrained': False, 'checkpoint_path': '', 'strict': False, 'dim': 384, 'mul': 1}
model_s.name                         : de_vit_small_patch16_224_dino       
model_s.kwargs                       : {'pretrained': False, 'checkpoint_path': '', 'strict': False, 'img_size': 256, 'students': [3, 6, 9], 'depth': 9}
model.name                           : vitad                               
model.kwargs                         : {'pretrained': False, 'checkpoint_path': '', 'strict': True, 'model_t': Namespace(name='vit_small_patch16_224_dino', kwargs={'pretrained': True, 'checkpoint_path': '', 'pretrained_strict': False, 'strict': True, 'img_size': 256, 'teachers': [3, 6, 9], 'neck': [12]}), 'model_f': Namespace(name='fusion', kwargs={'pretrained': False, 'checkpoint_path': '', 'strict': False, 'dim': 384, 'mul': 1}), 'model_s': Namespace(name='de_vit_small_patch16_224_dino', kwargs={'pretrained': False, 'checkpoint_path': '', 'strict': False, 'img_size': 256, 'students': [3, 6, 9], 'depth': 9})}
seed                                 : 42                                  
size                                 : 256                                 
warmup_epochs                        : 0                                   
test_start_epoch                     : 100                                 
test_per_epoch                       : 10                                  
batch_train                          : 8                                   
batch_test_per                       : 8                                   
lr                                   : 0.0001                              
weight_decay                         : 0.0001                              
cfg_path                             : configs.vitad.vitad_insplad         
mode                                 : train                               
sleep                                : -1                                  
memory                               : -1                                  
dist_url                             : env://                              
logger_rank                          : 0                                   
opts                                 : []                                  
command                              : python3 -m torch.distributed.launch --nproc_per_node=$nproc_per_node --nnodes=$nnodes --node_rank=$node_rank --master_addr=$master_addr --master_port=$master_port --use_env run.py -c configs.vitad.vitad_insplad -m train --sleep -1 --memory -1 --dist_url env:// --logger_rank 0 
task_start_time                      : 100616.908311                       
dist                                 : False                               
world_size                           : 1                                   
rank                                 : 0                                   
local_rank                           : 0                                   
ngpus_per_node                       : 1                                   
nnodes                               : 1                                   
master                               : True                                
logdir                               : runs/ViTADTrainer_configs_vitad_vitad_insplad_20251209-180225
logger.filters                       : []                                  
logger.name                          : root                                
logger.level                         : 20                                  
logger.parent                        : None                                
logger.propagate                     : True                                
logger.disabled                      : False                               
logdir_train                         : runs/ViTADTrainer_configs_vitad_vitad_insplad_20251209-180225/show_train
logdir_test                          : runs/ViTADTrainer_configs_vitad_vitad_insplad_20251209-180225/show_test
2025-12-09 18:02:27,365 - ==> Starting training with 1 nodes x 1 GPUs
2025-12-09 18:02:56,364 - Train: 0.05% [50/97600]  [0.1/100.0] [batch_t 0.098 (0.138)] [data_t 0.002] [optim_t 0.097] [lr 0.000100] [cos 1.222 (1.571)]
2025-12-09 18:03:00,521 - Train: 0.10% [100/97600]  [0.1/100.0] [batch_t 0.075 (0.083)] [data_t 0.002] [optim_t 0.073] [lr 0.000100] [cos 0.906 (1.041)]
2025-12-09 18:03:04,313 - Train: 0.15% [150/97600]  [0.2/100.0] [batch_t 0.076 (0.076)] [data_t 0.002] [optim_t 0.074] [lr 0.000100] [cos 0.816 (0.851)]
2025-12-09 18:03:08,178 - Train: 0.20% [200/97600]  [0.2/100.0] [batch_t 0.078 (0.077)] [data_t 0.002] [optim_t 0.076] [lr 0.000100] [cos 0.683 (0.759)]
2025-12-09 18:03:12,126 - Train: 0.26% [250/97600]  [0.3/100.0] [batch_t 0.080 (0.079)] [data_t 0.002] [optim_t 0.078] [lr 0.000100] [cos 0.660 (0.699)]
2025-12-09 18:03:16,157 - Train: 0.31% [300/97600]  [0.3/100.0] [batch_t 0.081 (0.081)] [data_t 0.002] [optim_t 0.079] [lr 0.000100] [cos 0.667 (0.660)]
2025-12-09 18:03:20,228 - Train: 0.36% [350/97600]  [0.4/100.0] [batch_t 0.083 (0.081)] [data_t 0.002] [optim_t 0.081] [lr 0.000100] [cos 0.615 (0.625)]
2025-12-09 18:03:24,358 - Train: 0.41% [400/97600]  [0.4/100.0] [batch_t 0.083 (0.082)] [data_t 0.002] [optim_t 0.081] [lr 0.000100] [cos 0.596 (0.597)]
2025-12-09 18:03:28,612 - Train: 0.46% [450/97600]  [0.5/100.0] [batch_t 0.085 (0.085)] [data_t 0.002] [optim_t 0.083] [lr 0.000100] [cos 0.572 (0.576)]
2025-12-09 18:03:32,925 - Train: 0.51% [500/97600]  [0.5/100.0] [batch_t 0.087 (0.086)] [data_t 0.002] [optim_t 0.085] [lr 0.000100] [cos 0.556 (0.552)]
2025-12-09 18:03:37,294 - Train: 0.56% [550/97600]  [0.6/100.0] [batch_t 0.088 (0.087)] [data_t 0.002] [optim_t 0.086] [lr 0.000100] [cos 0.590 (0.542)]
2025-12-09 18:03:41,687 - Train: 0.61% [600/97600]  [0.6/100.0] [batch_t 0.088 (0.088)] [data_t 0.002] [optim_t 0.086] [lr 0.000100] [cos 0.536 (0.517)]
2025-12-09 18:03:46,105 - Train: 0.67% [650/97600]  [0.7/100.0] [batch_t 0.089 (0.088)] [data_t 0.002] [optim_t 0.087] [lr 0.000100] [cos 0.522 (0.511)]
2025-12-09 18:03:50,541 - Train: 0.72% [700/97600]  [0.7/100.0] [batch_t 0.089 (0.089)] [data_t 0.002] [optim_t 0.087] [lr 0.000100] [cos 0.528 (0.499)]
2025-12-09 18:03:54,979 - Train: 0.77% [750/97600]  [0.8/100.0] [batch_t 0.089 (0.089)] [data_t 0.002] [optim_t 0.088] [lr 0.000100] [cos 0.469 (0.486)]
2025-12-09 18:03:59,447 - Train: 0.82% [800/97600]  [0.8/100.0] [batch_t 0.089 (0.089)] [data_t 0.002] [optim_t 0.087] [lr 0.000100] [cos 0.442 (0.483)]
2025-12-09 18:04:03,894 - Train: 0.87% [850/97600]  [0.9/100.0] [batch_t 0.088 (0.089)] [data_t 0.002] [optim_t 0.087] [lr 0.000100] [cos 0.469 (0.476)]
2025-12-09 18:04:08,375 - Train: 0.92% [900/97600]  [0.9/100.0] [batch_t 0.089 (0.089)] [data_t 0.002] [optim_t 0.088] [lr 0.000100] [cos 0.450 (0.463)]
2025-12-09 18:04:12,848 - Train: 0.97% [950/97600]  [1.0/100.0] [batch_t 0.089 (0.089)] [data_t 0.002] [optim_t 0.087] [lr 0.000100] [cos 0.437 (0.456)]
2025-12-09 18:04:15,177 - ==> Total time: 0:01:49	 Eta: 3:00:27 	Logged in 'runs/ViTADTrainer_configs_vitad_vitad_insplad_20251209-180225'
2025-12-09 18:10:02,950 - Train: 1.02% [1000/97600]  [1.0/100.0] [batch_t 0.069 (0.077)] [data_t 0.001] [optim_t 0.068] [lr 0.000100] [cos 0.441 (0.450)]
2025-12-09 18:10:06,433 - Train: 1.08% [1050/97600]  [1.1/100.0] [batch_t 0.069 (0.070)] [data_t 0.001] [optim_t 0.068] [lr 0.000100] [cos 0.459 (0.441)]
2025-12-09 18:10:09,937 - Train: 1.13% [1100/97600]  [1.1/100.0] [batch_t 0.072 (0.070)] [data_t 0.002] [optim_t 0.070] [lr 0.000100] [cos 0.417 (0.437)]
2025-12-09 18:10:13,727 - Train: 1.18% [1150/97600]  [1.2/100.0] [batch_t 0.070 (0.076)] [data_t 0.002] [optim_t 0.069] [lr 0.000100] [cos 0.424 (0.427)]
2025-12-09 18:10:17,403 - Train: 1.23% [1200/97600]  [1.2/100.0] [batch_t 0.071 (0.073)] [data_t 0.002] [optim_t 0.070] [lr 0.000100] [cos 0.416 (0.425)]
2025-12-09 18:10:21,093 - Train: 1.28% [1250/97600]  [1.3/100.0] [batch_t 0.072 (0.074)] [data_t 0.002] [optim_t 0.071] [lr 0.000100] [cos 0.405 (0.418)]
2025-12-09 18:10:24,731 - Train: 1.33% [1300/97600]  [1.3/100.0] [batch_t 0.072 (0.073)] [data_t 0.002] [optim_t 0.070] [lr 0.000100] [cos 0.403 (0.419)]
2025-12-09 18:10:28,375 - Train: 1.38% [1350/97600]  [1.4/100.0] [batch_t 0.074 (0.073)] [data_t 0.002] [optim_t 0.072] [lr 0.000100] [cos 0.389 (0.413)]
2025-12-09 18:10:32,027 - Train: 1.43% [1400/97600]  [1.4/100.0] [batch_t 0.074 (0.073)] [data_t 0.002] [optim_t 0.072] [lr 0.000100] [cos 0.406 (0.404)]
2025-12-09 18:10:35,806 - Train: 1.49% [1450/97600]  [1.5/100.0] [batch_t 0.076 (0.075)] [data_t 0.002] [optim_t 0.074] [lr 0.000100] [cos 0.383 (0.398)]
2025-12-09 18:10:39,723 - Train: 1.54% [1500/97600]  [1.5/100.0] [batch_t 0.079 (0.078)] [data_t 0.002] [optim_t 0.077] [lr 0.000100] [cos 0.392 (0.400)]
2025-12-09 18:10:43,651 - Train: 1.59% [1550/97600]  [1.6/100.0] [batch_t 0.080 (0.078)] [data_t 0.003] [optim_t 0.078] [lr 0.000100] [cos 0.417 (0.395)]
2025-12-09 18:10:47,648 - Train: 1.64% [1600/97600]  [1.6/100.0] [batch_t 0.081 (0.080)] [data_t 0.002] [optim_t 0.079] [lr 0.000100] [cos 0.402 (0.390)]
2025-12-09 18:10:51,656 - Train: 1.69% [1650/97600]  [1.7/100.0] [batch_t 0.083 (0.080)] [data_t 0.002] [optim_t 0.081] [lr 0.000100] [cos 0.377 (0.387)]
2025-12-09 18:10:55,732 - Train: 1.74% [1700/97600]  [1.7/100.0] [batch_t 0.080 (0.081)] [data_t 0.002] [optim_t 0.079] [lr 0.000100] [cos 0.387 (0.381)]
2025-12-09 18:10:59,871 - Train: 1.79% [1750/97600]  [1.8/100.0] [batch_t 0.081 (0.083)] [data_t 0.002] [optim_t 0.079] [lr 0.000100] [cos 0.337 (0.374)]
2025-12-09 18:11:03,991 - Train: 1.84% [1800/97600]  [1.8/100.0] [batch_t 0.085 (0.082)] [data_t 0.002] [optim_t 0.083] [lr 0.000100] [cos 0.436 (0.376)]
2025-12-09 18:11:08,200 - Train: 1.90% [1850/97600]  [1.9/100.0] [batch_t 0.084 (0.084)] [data_t 0.002] [optim_t 0.082] [lr 0.000100] [cos 0.383 (0.380)]
2025-12-09 18:11:12,429 - Train: 1.95% [1900/97600]  [1.9/100.0] [batch_t 0.084 (0.084)] [data_t 0.002] [optim_t 0.082] [lr 0.000100] [cos 0.397 (0.371)]
2025-12-09 18:11:16,907 - Train: 2.00% [1950/97600]  [2.0/100.0] [batch_t 0.089 (0.089)] [data_t 0.002] [optim_t 0.087] [lr 0.000100] [cos 0.368 (0.370)]
2025-12-09 18:11:17,089 - ==> Total time: 0:08:51	 Eta: 7:13:52 	Logged in 'runs/ViTADTrainer_configs_vitad_vitad_insplad_20251209-180225'
2025-12-09 18:12:06,376 - Train: 2.05% [2000/97600]  [2.0/100.0] [batch_t 0.072 (0.105)] [data_t 0.002] [optim_t 0.070] [lr 0.000100] [cos 0.351 (0.366)]
2025-12-09 18:12:09,951 - Train: 2.10% [2050/97600]  [2.1/100.0] [batch_t 0.072 (0.071)] [data_t 0.002] [optim_t 0.070] [lr 0.000100] [cos 0.365 (0.358)]
2025-12-09 18:12:13,682 - Train: 2.15% [2100/97600]  [2.2/100.0] [batch_t 0.117 (0.074)] [data_t 0.002] [optim_t 0.115] [lr 0.000100] [cos 0.371 (0.358)]
2025-12-09 18:12:17,533 - Train: 2.20% [2150/97600]  [2.2/100.0] [batch_t 0.077 (0.077)] [data_t 0.002] [optim_t 0.075] [lr 0.000100] [cos 0.351 (0.358)]
2025-12-09 18:12:21,485 - Train: 2.25% [2200/97600]  [2.3/100.0] [batch_t 0.079 (0.079)] [data_t 0.002] [optim_t 0.077] [lr 0.000100] [cos 0.353 (0.353)]
2025-12-09 18:12:25,490 - Train: 2.31% [2250/97600]  [2.3/100.0] [batch_t 0.079 (0.080)] [data_t 0.002] [optim_t 0.077] [lr 0.000100] [cos 0.378 (0.353)]
2025-12-09 18:12:29,553 - Train: 2.36% [2300/97600]  [2.4/100.0] [batch_t 0.082 (0.081)] [data_t 0.002] [optim_t 0.080] [lr 0.000100] [cos 0.350 (0.348)]
2025-12-09 18:12:33,656 - Train: 2.41% [2350/97600]  [2.4/100.0] [batch_t 0.081 (0.082)] [data_t 0.002] [optim_t 0.080] [lr 0.000100] [cos 0.341 (0.345)]
2025-12-09 18:12:37,834 - Train: 2.46% [2400/97600]  [2.5/100.0] [batch_t 0.084 (0.083)] [data_t 0.002] [optim_t 0.082] [lr 0.000100] [cos 0.334 (0.344)]
2025-12-09 18:12:42,068 - Train: 2.51% [2450/97600]  [2.5/100.0] [batch_t 0.085 (0.085)] [data_t 0.002] [optim_t 0.083] [lr 0.000100] [cos 0.334 (0.336)]
2025-12-09 18:12:46,361 - Train: 2.56% [2500/97600]  [2.6/100.0] [batch_t 0.085 (0.086)] [data_t 0.002] [optim_t 0.083] [lr 0.000100] [cos 0.324 (0.342)]
2025-12-09 18:12:50,702 - Train: 2.61% [2550/97600]  [2.6/100.0] [batch_t 0.086 (0.087)] [data_t 0.002] [optim_t 0.084] [lr 0.000100] [cos 0.327 (0.337)]
2025-12-09 18:12:55,087 - Train: 2.66% [2600/97600]  [2.7/100.0] [batch_t 0.087 (0.088)] [data_t 0.002] [optim_t 0.085] [lr 0.000100] [cos 0.320 (0.333)]
2025-12-09 18:12:59,499 - Train: 2.72% [2650/97600]  [2.7/100.0] [batch_t 0.087 (0.088)] [data_t 0.002] [optim_t 0.085] [lr 0.000100] [cos 0.312 (0.337)]
2025-12-09 18:13:03,905 - Train: 2.77% [2700/97600]  [2.8/100.0] [batch_t 0.087 (0.088)] [data_t 0.002] [optim_t 0.086] [lr 0.000100] [cos 0.309 (0.329)]
2025-12-09 18:13:08,308 - Train: 2.82% [2750/97600]  [2.8/100.0] [batch_t 0.090 (0.088)] [data_t 0.002] [optim_t 0.088] [lr 0.000100] [cos 0.325 (0.332)]
2025-12-09 18:13:12,716 - Train: 2.87% [2800/97600]  [2.9/100.0] [batch_t 0.087 (0.088)] [data_t 0.002] [optim_t 0.085] [lr 0.000100] [cos 0.305 (0.326)]
2025-12-09 18:13:17,423 - Train: 2.92% [2850/97600]  [2.9/100.0] [batch_t 0.097 (0.094)] [data_t 0.002] [optim_t 0.096] [lr 0.000100] [cos 0.327 (0.329)]
2025-12-09 18:13:22,137 - Train: 2.97% [2900/97600]  [3.0/100.0] [batch_t 0.092 (0.094)] [data_t 0.002] [optim_t 0.090] [lr 0.000100] [cos 0.323 (0.322)]
2025-12-09 18:13:24,680 - ==> Total time: 0:10:58	 Eta: 5:55:03 	Logged in 'runs/ViTADTrainer_configs_vitad_vitad_insplad_20251209-180225'
2025-12-09 18:14:13,584 - Train: 3.02% [2950/97600]  [3.0/100.0] [batch_t 0.109 (0.140)] [data_t 0.002] [optim_t 0.107] [lr 0.000100] [cos 0.297 (0.316)]
2025-12-09 18:14:17,774 - Train: 3.07% [3000/97600]  [3.1/100.0] [batch_t 0.076 (0.084)] [data_t 0.002] [optim_t 0.074] [lr 0.000100] [cos 0.327 (0.320)]
2025-12-09 18:14:21,562 - Train: 3.12% [3050/97600]  [3.1/100.0] [batch_t 0.076 (0.076)] [data_t 0.002] [optim_t 0.074] [lr 0.000100] [cos 0.326 (0.320)]
2025-12-09 18:14:25,434 - Train: 3.18% [3100/97600]  [3.2/100.0] [batch_t 0.078 (0.077)] [data_t 0.002] [optim_t 0.076] [lr 0.000100] [cos 0.345 (0.316)]
2025-12-09 18:14:29,415 - Train: 3.23% [3150/97600]  [3.2/100.0] [batch_t 0.082 (0.079)] [data_t 0.002] [optim_t 0.080] [lr 0.000100] [cos 0.318 (0.319)]
2025-12-09 18:14:33,497 - Train: 3.28% [3200/97600]  [3.3/100.0] [batch_t 0.081 (0.082)] [data_t 0.002] [optim_t 0.079] [lr 0.000100] [cos 0.309 (0.312)]
2025-12-09 18:14:37,769 - Train: 3.33% [3250/97600]  [3.3/100.0] [batch_t 0.090 (0.085)] [data_t 0.002] [optim_t 0.088] [lr 0.000100] [cos 0.313 (0.314)]
2025-12-09 18:14:42,861 - Train: 3.38% [3300/97600]  [3.4/100.0] [batch_t 0.100 (0.102)] [data_t 0.002] [optim_t 0.098] [lr 0.000100] [cos 0.308 (0.311)]
2025-12-09 18:14:47,584 - Train: 3.43% [3350/97600]  [3.4/100.0] [batch_t 0.090 (0.094)] [data_t 0.002] [optim_t 0.088] [lr 0.000100] [cos 0.294 (0.307)]
2025-12-09 18:14:52,086 - Train: 3.48% [3400/97600]  [3.5/100.0] [batch_t 0.091 (0.090)] [data_t 0.002] [optim_t 0.089] [lr 0.000100] [cos 0.305 (0.310)]
2025-12-09 18:14:56,552 - Train: 3.53% [3450/97600]  [3.5/100.0] [batch_t 0.089 (0.089)] [data_t 0.002] [optim_t 0.087] [lr 0.000100] [cos 0.364 (0.312)]
2025-12-09 18:15:01,093 - Train: 3.59% [3500/97600]  [3.6/100.0] [batch_t 0.089 (0.091)] [data_t 0.002] [optim_t 0.087] [lr 0.000100] [cos 0.304 (0.307)]
2025-12-09 18:15:05,589 - Train: 3.64% [3550/97600]  [3.6/100.0] [batch_t 0.091 (0.090)] [data_t 0.002] [optim_t 0.088] [lr 0.000100] [cos 0.291 (0.305)]
2025-12-09 18:15:10,196 - Train: 3.69% [3600/97600]  [3.7/100.0] [batch_t 0.092 (0.092)] [data_t 0.002] [optim_t 0.090] [lr 0.000100] [cos 0.310 (0.302)]
2025-12-09 18:15:14,965 - Train: 3.74% [3650/97600]  [3.7/100.0] [batch_t 0.115 (0.095)] [data_t 0.002] [optim_t 0.113] [lr 0.000100] [cos 0.312 (0.309)]
2025-12-09 18:15:21,135 - Train: 3.79% [3700/97600]  [3.8/100.0] [batch_t 0.134 (0.123)] [data_t 0.002] [optim_t 0.132] [lr 0.000100] [cos 0.300 (0.305)]
2025-12-09 18:15:28,539 - Train: 3.84% [3750/97600]  [3.8/100.0] [batch_t 0.133 (0.148)] [data_t 0.002] [optim_t 0.131] [lr 0.000100] [cos 0.297 (0.302)]
2025-12-09 18:15:35,466 - Train: 3.89% [3800/97600]  [3.9/100.0] [batch_t 0.133 (0.138)] [data_t 0.002] [optim_t 0.131] [lr 0.000100] [cos 0.277 (0.302)]
2025-12-09 18:15:42,149 - Train: 3.94% [3850/97600]  [3.9/100.0] [batch_t 0.134 (0.134)] [data_t 0.002] [optim_t 0.132] [lr 0.000100] [cos 0.318 (0.294)]
2025-12-09 18:15:48,845 - Train: 4.00% [3900/97600]  [4.0/100.0] [batch_t 0.133 (0.134)] [data_t 0.002] [optim_t 0.131] [lr 0.000100] [cos 0.302 (0.294)]
2025-12-09 18:15:49,377 - ==> Total time: 0:13:23	 Eta: 5:21:25 	Logged in 'runs/ViTADTrainer_configs_vitad_vitad_insplad_20251209-180225'
2025-12-09 18:16:48,971 - Train: 4.05% [3950/97600]  [4.0/100.0] [batch_t 0.096 (0.121)] [data_t 0.002] [optim_t 0.094] [lr 0.000100] [cos 0.302 (0.296)]
2025-12-09 18:16:53,196 - Train: 4.10% [4000/97600]  [4.1/100.0] [batch_t 0.079 (0.084)] [data_t 0.002] [optim_t 0.077] [lr 0.000100] [cos 0.292 (0.293)]
2025-12-09 18:16:57,089 - Train: 4.15% [4050/97600]  [4.1/100.0] [batch_t 0.081 (0.078)] [data_t 0.002] [optim_t 0.079] [lr 0.000100] [cos 0.308 (0.295)]
2025-12-09 18:17:01,109 - Train: 4.20% [4100/97600]  [4.2/100.0] [batch_t 0.089 (0.080)] [data_t 0.002] [optim_t 0.087] [lr 0.000100] [cos 0.259 (0.290)]
2025-12-09 18:17:05,198 - Train: 4.25% [4150/97600]  [4.3/100.0] [batch_t 0.083 (0.082)] [data_t 0.002] [optim_t 0.081] [lr 0.000100] [cos 0.292 (0.292)]
2025-12-09 18:17:09,441 - Train: 4.30% [4200/97600]  [4.3/100.0] [batch_t 0.084 (0.085)] [data_t 0.002] [optim_t 0.082] [lr 0.000100] [cos 0.319 (0.292)]
2025-12-09 18:17:13,804 - Train: 4.35% [4250/97600]  [4.4/100.0] [batch_t 0.088 (0.087)] [data_t 0.002] [optim_t 0.086] [lr 0.000100] [cos 0.291 (0.286)]
2025-12-09 18:17:18,511 - Train: 4.41% [4300/97600]  [4.4/100.0] [batch_t 0.105 (0.094)] [data_t 0.002] [optim_t 0.103] [lr 0.000100] [cos 0.292 (0.285)]
2025-12-09 18:17:23,861 - Train: 4.46% [4350/97600]  [4.5/100.0] [batch_t 0.106 (0.107)] [data_t 0.002] [optim_t 0.104] [lr 0.000100] [cos 0.280 (0.286)]
2025-12-09 18:17:28,989 - Train: 4.51% [4400/97600]  [4.5/100.0] [batch_t 0.099 (0.102)] [data_t 0.002] [optim_t 0.097] [lr 0.000100] [cos 0.287 (0.285)]
2025-12-09 18:17:33,743 - Train: 4.56% [4450/97600]  [4.6/100.0] [batch_t 0.092 (0.095)] [data_t 0.002] [optim_t 0.090] [lr 0.000100] [cos 0.321 (0.289)]
2025-12-09 18:17:38,342 - Train: 4.61% [4500/97600]  [4.6/100.0] [batch_t 0.089 (0.092)] [data_t 0.002] [optim_t 0.087] [lr 0.000100] [cos 0.281 (0.286)]
2025-12-09 18:17:42,861 - Train: 4.66% [4550/97600]  [4.7/100.0] [batch_t 0.090 (0.090)] [data_t 0.002] [optim_t 0.088] [lr 0.000100] [cos 0.296 (0.284)]
2025-12-09 18:17:47,408 - Train: 4.71% [4600/97600]  [4.7/100.0] [batch_t 0.090 (0.091)] [data_t 0.002] [optim_t 0.088] [lr 0.000100] [cos 0.270 (0.280)]
2025-12-09 18:17:51,958 - Train: 4.76% [4650/97600]  [4.8/100.0] [batch_t 0.091 (0.091)] [data_t 0.002] [optim_t 0.089] [lr 0.000100] [cos 0.300 (0.280)]
2025-12-09 18:17:56,503 - Train: 4.82% [4700/97600]  [4.8/100.0] [batch_t 0.090 (0.091)] [data_t 0.002] [optim_t 0.088] [lr 0.000100] [cos 0.291 (0.279)]
2025-12-09 18:18:01,076 - Train: 4.87% [4750/97600]  [4.9/100.0] [batch_t 0.091 (0.091)] [data_t 0.002] [optim_t 0.090] [lr 0.000100] [cos 0.276 (0.279)]
2025-12-09 18:18:05,737 - Train: 4.92% [4800/97600]  [4.9/100.0] [batch_t 0.091 (0.093)] [data_t 0.002] [optim_t 0.089] [lr 0.000100] [cos 0.256 (0.274)]
2025-12-09 18:18:10,399 - Train: 4.97% [4850/97600]  [5.0/100.0] [batch_t 0.092 (0.093)] [data_t 0.002] [optim_t 0.090] [lr 0.000100] [cos 0.291 (0.276)]
2025-12-09 18:18:13,180 - ==> Total time: 0:15:47	 Eta: 5:00:00 	Logged in 'runs/ViTADTrainer_configs_vitad_vitad_insplad_20251209-180225'
2025-12-09 18:19:02,931 - Train: 5.02% [4900/97600]  [5.0/100.0] [batch_t 0.131 (0.146)] [data_t 0.002] [optim_t 0.129] [lr 0.000100] [cos 0.259 (0.277)]
2025-12-09 18:19:08,741 - Train: 5.07% [4950/97600]  [5.1/100.0] [batch_t 0.104 (0.116)] [data_t 0.003] [optim_t 0.102] [lr 0.000100] [cos 0.289 (0.273)]
2025-12-09 18:19:13,486 - Train: 5.12% [5000/97600]  [5.1/100.0] [batch_t 0.089 (0.095)] [data_t 0.002] [optim_t 0.087] [lr 0.000100] [cos 0.270 (0.271)]
2025-12-09 18:19:18,048 - Train: 5.17% [5050/97600]  [5.2/100.0] [batch_t 0.093 (0.091)] [data_t 0.002] [optim_t 0.091] [lr 0.000100] [cos 0.274 (0.272)]
2025-12-09 18:19:23,661 - Train: 5.23% [5100/97600]  [5.2/100.0] [batch_t 0.112 (0.112)] [data_t 0.002] [optim_t 0.110] [lr 0.000100] [cos 0.284 (0.274)]
2025-12-09 18:19:29,157 - Train: 5.28% [5150/97600]  [5.3/100.0] [batch_t 0.107 (0.110)] [data_t 0.002] [optim_t 0.106] [lr 0.000100] [cos 0.288 (0.276)]
2025-12-09 18:19:34,323 - Train: 5.33% [5200/97600]  [5.3/100.0] [batch_t 0.100 (0.103)] [data_t 0.002] [optim_t 0.099] [lr 0.000100] [cos 0.275 (0.272)]
2025-12-09 18:19:39,212 - Train: 5.38% [5250/97600]  [5.4/100.0] [batch_t 0.095 (0.098)] [data_t 0.002] [optim_t 0.093] [lr 0.000100] [cos 0.266 (0.269)]
2025-12-09 18:19:43,927 - Train: 5.43% [5300/97600]  [5.4/100.0] [batch_t 0.093 (0.094)] [data_t 0.002] [optim_t 0.091] [lr 0.000100] [cos 0.314 (0.271)]
2025-12-09 18:19:48,619 - Train: 5.48% [5350/97600]  [5.5/100.0] [batch_t 0.094 (0.094)] [data_t 0.002] [optim_t 0.092] [lr 0.000100] [cos 0.271 (0.268)]
2025-12-09 18:19:53,397 - Train: 5.53% [5400/97600]  [5.5/100.0] [batch_t 0.097 (0.095)] [data_t 0.002] [optim_t 0.094] [lr 0.000100] [cos 0.262 (0.268)]
2025-12-09 18:19:58,309 - Train: 5.58% [5450/97600]  [5.6/100.0] [batch_t 0.099 (0.098)] [data_t 0.002] [optim_t 0.097] [lr 0.000100] [cos 0.248 (0.267)]
2025-12-09 18:20:03,404 - Train: 5.64% [5500/97600]  [5.6/100.0] [batch_t 0.103 (0.102)] [data_t 0.002] [optim_t 0.101] [lr 0.000100] [cos 0.284 (0.266)]
2025-12-09 18:20:08,649 - Train: 5.69% [5550/97600]  [5.7/100.0] [batch_t 0.113 (0.105)] [data_t 0.002] [optim_t 0.111] [lr 0.000100] [cos 0.276 (0.263)]
2025-12-09 18:20:14,211 - Train: 5.74% [5600/97600]  [5.7/100.0] [batch_t 0.112 (0.111)] [data_t 0.002] [optim_t 0.110] [lr 0.000100] [cos 0.267 (0.264)]
2025-12-09 18:20:20,491 - Train: 5.79% [5650/97600]  [5.8/100.0] [batch_t 0.133 (0.125)] [data_t 0.002] [optim_t 0.131] [lr 0.000100] [cos 0.248 (0.268)]
2025-12-09 18:20:27,165 - Train: 5.84% [5700/97600]  [5.8/100.0] [batch_t 0.133 (0.133)] [data_t 0.002] [optim_t 0.131] [lr 0.000100] [cos 0.265 (0.268)]
2025-12-09 18:20:33,857 - Train: 5.89% [5750/97600]  [5.9/100.0] [batch_t 0.134 (0.134)] [data_t 0.002] [optim_t 0.132] [lr 0.000100] [cos 0.259 (0.266)]
2025-12-09 18:20:40,538 - Train: 5.94% [5800/97600]  [5.9/100.0] [batch_t 0.133 (0.133)] [data_t 0.002] [optim_t 0.131] [lr 0.000100] [cos 0.267 (0.263)]
2025-12-09 18:20:47,222 - Train: 5.99% [5850/97600]  [6.0/100.0] [batch_t 0.133 (0.134)] [data_t 0.002] [optim_t 0.131] [lr 0.000100] [cos 0.258 (0.265)]
2025-12-09 18:20:48,027 - ==> Total time: 0:18:22	 Eta: 4:47:48 	Logged in 'runs/ViTADTrainer_configs_vitad_vitad_insplad_20251209-180225'
2025-12-09 18:21:38,695 - Train: 6.05% [5900/97600]  [6.0/100.0] [batch_t 0.132 (0.136)] [data_t 0.002] [optim_t 0.130] [lr 0.000100] [cos 0.265 (0.259)]
2025-12-09 18:21:45,116 - Train: 6.10% [5950/97600]  [6.1/100.0] [batch_t 0.123 (0.128)] [data_t 0.002] [optim_t 0.121] [lr 0.000100] [cos 0.255 (0.258)]
2025-12-09 18:21:51,078 - Train: 6.15% [6000/97600]  [6.1/100.0] [batch_t 0.115 (0.119)] [data_t 0.002] [optim_t 0.113] [lr 0.000100] [cos 0.276 (0.258)]
2025-12-09 18:21:56,745 - Train: 6.20% [6050/97600]  [6.2/100.0] [batch_t 0.112 (0.113)] [data_t 0.002] [optim_t 0.110] [lr 0.000100] [cos 0.257 (0.261)]
2025-12-09 18:22:02,227 - Train: 6.25% [6100/97600]  [6.2/100.0] [batch_t 0.108 (0.110)] [data_t 0.002] [optim_t 0.106] [lr 0.000100] [cos 0.255 (0.260)]
2025-12-09 18:22:07,583 - Train: 6.30% [6150/97600]  [6.3/100.0] [batch_t 0.106 (0.107)] [data_t 0.002] [optim_t 0.105] [lr 0.000100] [cos 0.253 (0.258)]
2025-12-09 18:22:12,915 - Train: 6.35% [6200/97600]  [6.4/100.0] [batch_t 0.106 (0.106)] [data_t 0.002] [optim_t 0.105] [lr 0.000100] [cos 0.258 (0.257)]
2025-12-09 18:22:18,412 - Train: 6.40% [6250/97600]  [6.4/100.0] [batch_t 0.107 (0.110)] [data_t 0.002] [optim_t 0.105] [lr 0.000100] [cos 0.258 (0.260)]
2025-12-09 18:22:24,539 - Train: 6.45% [6300/97600]  [6.5/100.0] [batch_t 0.127 (0.122)] [data_t 0.002] [optim_t 0.125] [lr 0.000100] [cos 0.246 (0.259)]
2025-12-09 18:22:30,989 - Train: 6.51% [6350/97600]  [6.5/100.0] [batch_t 0.130 (0.129)] [data_t 0.002] [optim_t 0.128] [lr 0.000100] [cos 0.242 (0.255)]
2025-12-09 18:22:37,546 - Train: 6.56% [6400/97600]  [6.6/100.0] [batch_t 0.132 (0.131)] [data_t 0.002] [optim_t 0.130] [lr 0.000100] [cos 0.258 (0.256)]
2025-12-09 18:22:44,137 - Train: 6.61% [6450/97600]  [6.6/100.0] [batch_t 0.132 (0.132)] [data_t 0.002] [optim_t 0.130] [lr 0.000100] [cos 0.274 (0.254)]
2025-12-09 18:22:50,728 - Train: 6.66% [6500/97600]  [6.7/100.0] [batch_t 0.131 (0.132)] [data_t 0.002] [optim_t 0.130] [lr 0.000100] [cos 0.267 (0.252)]
2025-12-09 18:22:57,206 - Train: 6.71% [6550/97600]  [6.7/100.0] [batch_t 0.127 (0.129)] [data_t 0.002] [optim_t 0.125] [lr 0.000100] [cos 0.232 (0.251)]
2025-12-09 18:23:03,354 - Train: 6.76% [6600/97600]  [6.8/100.0] [batch_t 0.120 (0.123)] [data_t 0.002] [optim_t 0.118] [lr 0.000100] [cos 0.277 (0.257)]
2025-12-09 18:23:09,346 - Train: 6.81% [6650/97600]  [6.8/100.0] [batch_t 0.117 (0.120)] [data_t 0.002] [optim_t 0.115] [lr 0.000100] [cos 0.253 (0.252)]
2025-12-09 18:23:15,180 - Train: 6.86% [6700/97600]  [6.9/100.0] [batch_t 0.116 (0.117)] [data_t 0.002] [optim_t 0.114] [lr 0.000100] [cos 0.240 (0.254)]
2025-12-09 18:23:21,303 - Train: 6.92% [6750/97600]  [6.9/100.0] [batch_t 0.129 (0.122)] [data_t 0.002] [optim_t 0.127] [lr 0.000100] [cos 0.230 (0.251)]
2025-12-09 18:23:27,927 - Train: 6.97% [6800/97600]  [7.0/100.0] [batch_t 0.133 (0.132)] [data_t 0.002] [optim_t 0.131] [lr 0.000100] [cos 0.257 (0.254)]
2025-12-09 18:23:32,194 - ==> Total time: 0:21:06	 Eta: 4:40:24 	Logged in 'runs/ViTADTrainer_configs_vitad_vitad_insplad_20251209-180225'
2025-12-09 18:24:19,549 - Train: 7.02% [6850/97600]  [7.0/100.0] [batch_t 0.125 (0.140)] [data_t 0.002] [optim_t 0.123] [lr 0.000100] [cos 0.246 (0.249)]
2025-12-09 18:24:24,864 - Train: 7.07% [6900/97600]  [7.1/100.0] [batch_t 0.091 (0.106)] [data_t 0.002] [optim_t 0.090] [lr 0.000100] [cos 0.239 (0.247)]
2025-12-09 18:24:29,283 - Train: 7.12% [6950/97600]  [7.1/100.0] [batch_t 0.091 (0.088)] [data_t 0.002] [optim_t 0.089] [lr 0.000100] [cos 0.247 (0.251)]
2025-12-09 18:24:33,561 - Train: 7.17% [7000/97600]  [7.2/100.0] [batch_t 0.084 (0.085)] [data_t 0.002] [optim_t 0.083] [lr 0.000100] [cos 0.268 (0.248)]
2025-12-09 18:24:37,919 - Train: 7.22% [7050/97600]  [7.2/100.0] [batch_t 0.092 (0.087)] [data_t 0.002] [optim_t 0.090] [lr 0.000100] [cos 0.235 (0.246)]
2025-12-09 18:24:42,447 - Train: 7.27% [7100/97600]  [7.3/100.0] [batch_t 0.091 (0.090)] [data_t 0.002] [optim_t 0.089] [lr 0.000100] [cos 0.262 (0.248)]
2025-12-09 18:24:47,187 - Train: 7.33% [7150/97600]  [7.3/100.0] [batch_t 0.096 (0.095)] [data_t 0.002] [optim_t 0.094] [lr 0.000100] [cos 0.251 (0.248)]
2025-12-09 18:24:52,137 - Train: 7.38% [7200/97600]  [7.4/100.0] [batch_t 0.101 (0.099)] [data_t 0.002] [optim_t 0.099] [lr 0.000100] [cos 0.238 (0.245)]
2025-12-09 18:24:57,362 - Train: 7.43% [7250/97600]  [7.4/100.0] [batch_t 0.105 (0.104)] [data_t 0.002] [optim_t 0.103] [lr 0.000100] [cos 0.249 (0.248)]
2025-12-09 18:25:02,735 - Train: 7.48% [7300/97600]  [7.5/100.0] [batch_t 0.107 (0.107)] [data_t 0.002] [optim_t 0.105] [lr 0.000100] [cos 0.229 (0.245)]
2025-12-09 18:25:08,015 - Train: 7.53% [7350/97600]  [7.5/100.0] [batch_t 0.103 (0.105)] [data_t 0.002] [optim_t 0.101] [lr 0.000100] [cos 0.256 (0.249)]
2025-12-09 18:25:13,061 - Train: 7.58% [7400/97600]  [7.6/100.0] [batch_t 0.097 (0.101)] [data_t 0.002] [optim_t 0.095] [lr 0.000100] [cos 0.243 (0.246)]
2025-12-09 18:25:17,889 - Train: 7.63% [7450/97600]  [7.6/100.0] [batch_t 0.096 (0.096)] [data_t 0.002] [optim_t 0.094] [lr 0.000100] [cos 0.247 (0.246)]
2025-12-09 18:25:22,682 - Train: 7.68% [7500/97600]  [7.7/100.0] [batch_t 0.095 (0.096)] [data_t 0.002] [optim_t 0.093] [lr 0.000100] [cos 0.244 (0.246)]
2025-12-09 18:25:27,407 - Train: 7.74% [7550/97600]  [7.7/100.0] [batch_t 0.094 (0.094)] [data_t 0.002] [optim_t 0.092] [lr 0.000100] [cos 0.231 (0.247)]
2025-12-09 18:25:32,108 - Train: 7.79% [7600/97600]  [7.8/100.0] [batch_t 0.093 (0.094)] [data_t 0.002] [optim_t 0.091] [lr 0.000100] [cos 0.227 (0.245)]
2025-12-09 18:25:36,823 - Train: 7.84% [7650/97600]  [7.8/100.0] [batch_t 0.094 (0.094)] [data_t 0.002] [optim_t 0.092] [lr 0.000100] [cos 0.251 (0.245)]
2025-12-09 18:25:41,569 - Train: 7.89% [7700/97600]  [7.9/100.0] [batch_t 0.097 (0.095)] [data_t 0.002] [optim_t 0.095] [lr 0.000100] [cos 0.239 (0.242)]
2025-12-09 18:25:46,340 - Train: 7.94% [7750/97600]  [7.9/100.0] [batch_t 0.095 (0.095)] [data_t 0.002] [optim_t 0.093] [lr 0.000100] [cos 0.237 (0.244)]
2025-12-09 18:25:51,178 - Train: 7.99% [7800/97600]  [8.0/100.0] [batch_t 0.098 (0.097)] [data_t 0.002] [optim_t 0.096] [lr 0.000100] [cos 0.246 (0.237)]
2025-12-09 18:25:51,971 - ==> Total time: 0:23:26	 Eta: 4:29:30 	Logged in 'runs/ViTADTrainer_configs_vitad_vitad_insplad_20251209-180225'
2025-12-09 18:26:42,455 - Train: 8.04% [7850/97600]  [8.0/100.0] [batch_t 0.105 (0.127)] [data_t 0.002] [optim_t 0.103] [lr 0.000100] [cos 0.228 (0.241)]
2025-12-09 18:26:47,109 - Train: 8.09% [7900/97600]  [8.1/100.0] [batch_t 0.087 (0.093)] [data_t 0.002] [optim_t 0.085] [lr 0.000100] [cos 0.249 (0.239)]
2025-12-09 18:26:51,371 - Train: 8.15% [7950/97600]  [8.1/100.0] [batch_t 0.082 (0.085)] [data_t 0.002] [optim_t 0.080] [lr 0.000100] [cos 0.219 (0.237)]
2025-12-09 18:26:55,576 - Train: 8.20% [8000/97600]  [8.2/100.0] [batch_t 0.084 (0.084)] [data_t 0.002] [optim_t 0.082] [lr 0.000100] [cos 0.235 (0.243)]
2025-12-09 18:26:59,898 - Train: 8.25% [8050/97600]  [8.2/100.0] [batch_t 0.090 (0.086)] [data_t 0.002] [optim_t 0.088] [lr 0.000100] [cos 0.231 (0.237)]
2025-12-09 18:27:04,328 - Train: 8.30% [8100/97600]  [8.3/100.0] [batch_t 0.089 (0.088)] [data_t 0.002] [optim_t 0.087] [lr 0.000100] [cos 0.259 (0.242)]
2025-12-09 18:27:08,830 - Train: 8.35% [8150/97600]  [8.4/100.0] [batch_t 0.091 (0.090)] [data_t 0.002] [optim_t 0.089] [lr 0.000100] [cos 0.247 (0.238)]
2025-12-09 18:27:13,410 - Train: 8.40% [8200/97600]  [8.4/100.0] [batch_t 0.092 (0.091)] [data_t 0.002] [optim_t 0.090] [lr 0.000100] [cos 0.238 (0.241)]
2025-12-09 18:27:18,841 - Train: 8.45% [8250/97600]  [8.5/100.0] [batch_t 0.117 (0.108)] [data_t 0.002] [optim_t 0.115] [lr 0.000100] [cos 0.253 (0.237)]
2025-12-09 18:27:24,784 - Train: 8.50% [8300/97600]  [8.5/100.0] [batch_t 0.119 (0.119)] [data_t 0.002] [optim_t 0.117] [lr 0.000100] [cos 0.256 (0.239)]
2025-12-09 18:27:30,689 - Train: 8.56% [8350/97600]  [8.6/100.0] [batch_t 0.115 (0.118)] [data_t 0.002] [optim_t 0.113] [lr 0.000100] [cos 0.237 (0.238)]
2025-12-09 18:27:36,293 - Train: 8.61% [8400/97600]  [8.6/100.0] [batch_t 0.108 (0.112)] [data_t 0.002] [optim_t 0.106] [lr 0.000100] [cos 0.248 (0.235)]
2025-12-09 18:27:41,492 - Train: 8.66% [8450/97600]  [8.7/100.0] [batch_t 0.100 (0.104)] [data_t 0.002] [optim_t 0.098] [lr 0.000100] [cos 0.226 (0.237)]
2025-12-09 18:27:46,391 - Train: 8.71% [8500/97600]  [8.7/100.0] [batch_t 0.095 (0.098)] [data_t 0.002] [optim_t 0.093] [lr 0.000100] [cos 0.247 (0.235)]
2025-12-09 18:27:51,097 - Train: 8.76% [8550/97600]  [8.8/100.0] [batch_t 0.092 (0.094)] [data_t 0.002] [optim_t 0.090] [lr 0.000100] [cos 0.219 (0.235)]
2025-12-09 18:27:55,697 - Train: 8.81% [8600/97600]  [8.8/100.0] [batch_t 0.093 (0.092)] [data_t 0.002] [optim_t 0.091] [lr 0.000100] [cos 0.242 (0.236)]
2025-12-09 18:28:00,301 - Train: 8.86% [8650/97600]  [8.9/100.0] [batch_t 0.092 (0.092)] [data_t 0.002] [optim_t 0.089] [lr 0.000100] [cos 0.243 (0.234)]
2025-12-09 18:28:04,939 - Train: 8.91% [8700/97600]  [8.9/100.0] [batch_t 0.093 (0.093)] [data_t 0.002] [optim_t 0.091] [lr 0.000100] [cos 0.233 (0.235)]
2025-12-09 18:28:09,646 - Train: 8.97% [8750/97600]  [9.0/100.0] [batch_t 0.095 (0.094)] [data_t 0.002] [optim_t 0.093] [lr 0.000100] [cos 0.219 (0.234)]
2025-12-09 18:28:12,908 - ==> Total time: 0:25:47	 Eta: 4:20:42 	Logged in 'runs/ViTADTrainer_configs_vitad_vitad_insplad_20251209-180225'
2025-12-09 18:28:59,008 - Train: 9.02% [8800/97600]  [9.0/100.0] [batch_t 0.130 (0.145)] [data_t 0.002] [optim_t 0.128] [lr 0.000100] [cos 0.221 (0.235)]
2025-12-09 18:29:04,491 - Train: 9.07% [8850/97600]  [9.1/100.0] [batch_t 0.095 (0.110)] [data_t 0.002] [optim_t 0.093] [lr 0.000100] [cos 0.234 (0.232)]
2025-12-09 18:29:08,956 - Train: 9.12% [8900/97600]  [9.1/100.0] [batch_t 0.088 (0.089)] [data_t 0.002] [optim_t 0.086] [lr 0.000100] [cos 0.238 (0.235)]
2025-12-09 18:29:13,220 - Train: 9.17% [8950/97600]  [9.2/100.0] [batch_t 0.095 (0.085)] [data_t 0.002] [optim_t 0.093] [lr 0.000100] [cos 0.224 (0.234)]
2025-12-09 18:29:17,897 - Train: 9.22% [9000/97600]  [9.2/100.0] [batch_t 0.103 (0.093)] [data_t 0.002] [optim_t 0.101] [lr 0.000100] [cos 0.230 (0.229)]
2025-12-09 18:29:23,199 - Train: 9.27% [9050/97600]  [9.3/100.0] [batch_t 0.107 (0.106)] [data_t 0.002] [optim_t 0.105] [lr 0.000100] [cos 0.206 (0.231)]
2025-12-09 18:29:28,508 - Train: 9.32% [9100/97600]  [9.3/100.0] [batch_t 0.106 (0.106)] [data_t 0.002] [optim_t 0.103] [lr 0.000100] [cos 0.224 (0.229)]
2025-12-09 18:29:33,761 - Train: 9.38% [9150/97600]  [9.4/100.0] [batch_t 0.105 (0.105)] [data_t 0.002] [optim_t 0.103] [lr 0.000100] [cos 0.238 (0.231)]
2025-12-09 18:29:38,941 - Train: 9.43% [9200/97600]  [9.4/100.0] [batch_t 0.103 (0.103)] [data_t 0.002] [optim_t 0.101] [lr 0.000100] [cos 0.226 (0.230)]
2025-12-09 18:29:44,091 - Train: 9.48% [9250/97600]  [9.5/100.0] [batch_t 0.104 (0.103)] [data_t 0.003] [optim_t 0.101] [lr 0.000100] [cos 0.217 (0.233)]
2025-12-09 18:29:49,229 - Train: 9.53% [9300/97600]  [9.5/100.0] [batch_t 0.104 (0.103)] [data_t 0.002] [optim_t 0.101] [lr 0.000100] [cos 0.225 (0.229)]
2025-12-09 18:29:54,389 - Train: 9.58% [9350/97600]  [9.6/100.0] [batch_t 0.104 (0.103)] [data_t 0.002] [optim_t 0.102] [lr 0.000100] [cos 0.248 (0.228)]
2025-12-09 18:29:59,650 - Train: 9.63% [9400/97600]  [9.6/100.0] [batch_t 0.108 (0.105)] [data_t 0.002] [optim_t 0.106] [lr 0.000100] [cos 0.220 (0.228)]
2025-12-09 18:30:05,323 - Train: 9.68% [9450/97600]  [9.7/100.0] [batch_t 0.119 (0.113)] [data_t 0.002] [optim_t 0.117] [lr 0.000100] [cos 0.238 (0.226)]
2025-12-09 18:30:11,754 - Train: 9.73% [9500/97600]  [9.7/100.0] [batch_t 0.133 (0.128)] [data_t 0.002] [optim_t 0.131] [lr 0.000100] [cos 0.248 (0.231)]
2025-12-09 18:30:18,506 - Train: 9.78% [9550/97600]  [9.8/100.0] [batch_t 0.133 (0.135)] [data_t 0.002] [optim_t 0.131] [lr 0.000100] [cos 0.220 (0.233)]
2025-12-09 18:30:25,179 - Train: 9.84% [9600/97600]  [9.8/100.0] [batch_t 0.133 (0.133)] [data_t 0.002] [optim_t 0.131] [lr 0.000100] [cos 0.232 (0.229)]
2025-12-09 18:30:31,849 - Train: 9.89% [9650/97600]  [9.9/100.0] [batch_t 0.133 (0.133)] [data_t 0.002] [optim_t 0.131] [lr 0.000100] [cos 0.209 (0.230)]
2025-12-09 18:30:38,521 - Train: 9.94% [9700/97600]  [9.9/100.0] [batch_t 0.133 (0.133)] [data_t 0.002] [optim_t 0.132] [lr 0.000100] [cos 0.233 (0.228)]
2025-12-09 18:30:45,083 - Train: 9.99% [9750/97600]  [10.0/100.0] [batch_t 0.130 (0.131)] [data_t 0.002] [optim_t 0.128] [lr 0.000100] [cos 0.233 (0.226)]
