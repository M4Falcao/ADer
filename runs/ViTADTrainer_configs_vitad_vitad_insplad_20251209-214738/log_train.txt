2025-12-09 21:47:38,770 - ==> Logging on master GPU: 0
2025-12-09 21:47:38,770 - ==> Running Trainer: ViTADTrainer
2025-12-09 21:47:38,771 - ==> Using GPU: [0] for Training
2025-12-09 21:47:38,771 - ==> Building model
2025-12-09 21:47:38,942 - Loading pretrained weights from Hugging Face hub (timm/vit_small_patch16_224.dino)
2025-12-09 21:47:39,700 - HTTP Request: HEAD https://huggingface.co/timm/vit_small_patch16_224.dino/resolve/main/model.safetensors "HTTP/1.1 302 Found"
2025-12-09 21:47:39,709 - [timm/vit_small_patch16_224.dino] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-09 21:47:39,760 - Resized position embedding: (14, 14) to (16, 16).
2025-12-09 21:47:40,945 - 
------------------------------------ ViTAD ------------------------------------
| module                            | #parameters or shape   | #flops       |
|:----------------------------------|:-----------------------|:-------------|
| model                             | 38.586M                | 9.668G       |
|  net_t                            |  21.689M               |  5.544G      |
|   net_t.cls_token                 |   (1, 1, 384)          |              |
|   net_t.pos_embed                 |   (1, 257, 384)        |              |
|   net_t.patch_embed.proj          |   0.295M               |   75.497M    |
|    net_t.patch_embed.proj.weight  |    (384, 3, 16, 16)    |              |
|    net_t.patch_embed.proj.bias    |    (384,)              |              |
|   net_t.blocks                    |   21.294M              |   5.469G     |
|    net_t.blocks.0                 |    1.774M              |    0.456G    |
|     net_t.blocks.0.norm1          |     0.768K             |     0.493M   |
|      net_t.blocks.0.norm1.weight  |      (384,)            |              |
|      net_t.blocks.0.norm1.bias    |      (384,)            |              |
|     net_t.blocks.0.attn           |     0.591M             |     0.152G   |
|      net_t.blocks.0.attn.qkv      |      0.444M            |      0.114G  |
|      net_t.blocks.0.attn.proj     |      0.148M            |      37.896M |
|     net_t.blocks.0.norm2          |     0.768K             |     0.493M   |
|      net_t.blocks.0.norm2.weight  |      (384,)            |              |
|      net_t.blocks.0.norm2.bias    |      (384,)            |              |
|     net_t.blocks.0.mlp            |     1.182M             |     0.303G   |
|      net_t.blocks.0.mlp.fc1       |      0.591M            |      0.152G  |
|      net_t.blocks.0.mlp.fc2       |      0.59M             |      0.152G  |
|    net_t.blocks.1                 |    1.774M              |    0.456G    |
|     net_t.blocks.1.norm1          |     0.768K             |     0.493M   |
|      net_t.blocks.1.norm1.weight  |      (384,)            |              |
|      net_t.blocks.1.norm1.bias    |      (384,)            |              |
|     net_t.blocks.1.attn           |     0.591M             |     0.152G   |
|      net_t.blocks.1.attn.qkv      |      0.444M            |      0.114G  |
|      net_t.blocks.1.attn.proj     |      0.148M            |      37.896M |
|     net_t.blocks.1.norm2          |     0.768K             |     0.493M   |
|      net_t.blocks.1.norm2.weight  |      (384,)            |              |
|      net_t.blocks.1.norm2.bias    |      (384,)            |              |
|     net_t.blocks.1.mlp            |     1.182M             |     0.303G   |
|      net_t.blocks.1.mlp.fc1       |      0.591M            |      0.152G  |
|      net_t.blocks.1.mlp.fc2       |      0.59M             |      0.152G  |
|    net_t.blocks.2                 |    1.774M              |    0.456G    |
|     net_t.blocks.2.norm1          |     0.768K             |     0.493M   |
|      net_t.blocks.2.norm1.weight  |      (384,)            |              |
|      net_t.blocks.2.norm1.bias    |      (384,)            |              |
|     net_t.blocks.2.attn           |     0.591M             |     0.152G   |
|      net_t.blocks.2.attn.qkv      |      0.444M            |      0.114G  |
|      net_t.blocks.2.attn.proj     |      0.148M            |      37.896M |
|     net_t.blocks.2.norm2          |     0.768K             |     0.493M   |
|      net_t.blocks.2.norm2.weight  |      (384,)            |              |
|      net_t.blocks.2.norm2.bias    |      (384,)            |              |
|     net_t.blocks.2.mlp            |     1.182M             |     0.303G   |
|      net_t.blocks.2.mlp.fc1       |      0.591M            |      0.152G  |
|      net_t.blocks.2.mlp.fc2       |      0.59M             |      0.152G  |
|    net_t.blocks.3                 |    1.774M              |    0.456G    |
|     net_t.blocks.3.norm1          |     0.768K             |     0.493M   |
|      net_t.blocks.3.norm1.weight  |      (384,)            |              |
|      net_t.blocks.3.norm1.bias    |      (384,)            |              |
|     net_t.blocks.3.attn           |     0.591M             |     0.152G   |
|      net_t.blocks.3.attn.qkv      |      0.444M            |      0.114G  |
|      net_t.blocks.3.attn.proj     |      0.148M            |      37.896M |
|     net_t.blocks.3.norm2          |     0.768K             |     0.493M   |
|      net_t.blocks.3.norm2.weight  |      (384,)            |              |
|      net_t.blocks.3.norm2.bias    |      (384,)            |              |
|     net_t.blocks.3.mlp            |     1.182M             |     0.303G   |
|      net_t.blocks.3.mlp.fc1       |      0.591M            |      0.152G  |
|      net_t.blocks.3.mlp.fc2       |      0.59M             |      0.152G  |
|    net_t.blocks.4                 |    1.774M              |    0.456G    |
|     net_t.blocks.4.norm1          |     0.768K             |     0.493M   |
|      net_t.blocks.4.norm1.weight  |      (384,)            |              |
|      net_t.blocks.4.norm1.bias    |      (384,)            |              |
|     net_t.blocks.4.attn           |     0.591M             |     0.152G   |
|      net_t.blocks.4.attn.qkv      |      0.444M            |      0.114G  |
|      net_t.blocks.4.attn.proj     |      0.148M            |      37.896M |
|     net_t.blocks.4.norm2          |     0.768K             |     0.493M   |
|      net_t.blocks.4.norm2.weight  |      (384,)            |              |
|      net_t.blocks.4.norm2.bias    |      (384,)            |              |
|     net_t.blocks.4.mlp            |     1.182M             |     0.303G   |
|      net_t.blocks.4.mlp.fc1       |      0.591M            |      0.152G  |
|      net_t.blocks.4.mlp.fc2       |      0.59M             |      0.152G  |
|    net_t.blocks.5                 |    1.774M              |    0.456G    |
|     net_t.blocks.5.norm1          |     0.768K             |     0.493M   |
|      net_t.blocks.5.norm1.weight  |      (384,)            |              |
|      net_t.blocks.5.norm1.bias    |      (384,)            |              |
|     net_t.blocks.5.attn           |     0.591M             |     0.152G   |
|      net_t.blocks.5.attn.qkv      |      0.444M            |      0.114G  |
|      net_t.blocks.5.attn.proj     |      0.148M            |      37.896M |
|     net_t.blocks.5.norm2          |     0.768K             |     0.493M   |
|      net_t.blocks.5.norm2.weight  |      (384,)            |              |
|      net_t.blocks.5.norm2.bias    |      (384,)            |              |
|     net_t.blocks.5.mlp            |     1.182M             |     0.303G   |
|      net_t.blocks.5.mlp.fc1       |      0.591M            |      0.152G  |
|      net_t.blocks.5.mlp.fc2       |      0.59M             |      0.152G  |
|    net_t.blocks.6                 |    1.774M              |    0.456G    |
|     net_t.blocks.6.norm1          |     0.768K             |     0.493M   |
|      net_t.blocks.6.norm1.weight  |      (384,)            |              |
|      net_t.blocks.6.norm1.bias    |      (384,)            |              |
|     net_t.blocks.6.attn           |     0.591M             |     0.152G   |
|      net_t.blocks.6.attn.qkv      |      0.444M            |      0.114G  |
|      net_t.blocks.6.attn.proj     |      0.148M            |      37.896M |
|     net_t.blocks.6.norm2          |     0.768K             |     0.493M   |
|      net_t.blocks.6.norm2.weight  |      (384,)            |              |
|      net_t.blocks.6.norm2.bias    |      (384,)            |              |
|     net_t.blocks.6.mlp            |     1.182M             |     0.303G   |
|      net_t.blocks.6.mlp.fc1       |      0.591M            |      0.152G  |
|      net_t.blocks.6.mlp.fc2       |      0.59M             |      0.152G  |
|    net_t.blocks.7                 |    1.774M              |    0.456G    |
|     net_t.blocks.7.norm1          |     0.768K             |     0.493M   |
|      net_t.blocks.7.norm1.weight  |      (384,)            |              |
|      net_t.blocks.7.norm1.bias    |      (384,)            |              |
|     net_t.blocks.7.attn           |     0.591M             |     0.152G   |
|      net_t.blocks.7.attn.qkv      |      0.444M            |      0.114G  |
|      net_t.blocks.7.attn.proj     |      0.148M            |      37.896M |
|     net_t.blocks.7.norm2          |     0.768K             |     0.493M   |
|      net_t.blocks.7.norm2.weight  |      (384,)            |              |
|      net_t.blocks.7.norm2.bias    |      (384,)            |              |
|     net_t.blocks.7.mlp            |     1.182M             |     0.303G   |
|      net_t.blocks.7.mlp.fc1       |      0.591M            |      0.152G  |
|      net_t.blocks.7.mlp.fc2       |      0.59M             |      0.152G  |
|    net_t.blocks.8                 |    1.774M              |    0.456G    |
|     net_t.blocks.8.norm1          |     0.768K             |     0.493M   |
|      net_t.blocks.8.norm1.weight  |      (384,)            |              |
|      net_t.blocks.8.norm1.bias    |      (384,)            |              |
|     net_t.blocks.8.attn           |     0.591M             |     0.152G   |
|      net_t.blocks.8.attn.qkv      |      0.444M            |      0.114G  |
|      net_t.blocks.8.attn.proj     |      0.148M            |      37.896M |
|     net_t.blocks.8.norm2          |     0.768K             |     0.493M   |
|      net_t.blocks.8.norm2.weight  |      (384,)            |              |
|      net_t.blocks.8.norm2.bias    |      (384,)            |              |
|     net_t.blocks.8.mlp            |     1.182M             |     0.303G   |
|      net_t.blocks.8.mlp.fc1       |      0.591M            |      0.152G  |
|      net_t.blocks.8.mlp.fc2       |      0.59M             |      0.152G  |
|    net_t.blocks.9                 |    1.774M              |    0.456G    |
|     net_t.blocks.9.norm1          |     0.768K             |     0.493M   |
|      net_t.blocks.9.norm1.weight  |      (384,)            |              |
|      net_t.blocks.9.norm1.bias    |      (384,)            |              |
|     net_t.blocks.9.attn           |     0.591M             |     0.152G   |
|      net_t.blocks.9.attn.qkv      |      0.444M            |      0.114G  |
|      net_t.blocks.9.attn.proj     |      0.148M            |      37.896M |
|     net_t.blocks.9.norm2          |     0.768K             |     0.493M   |
|      net_t.blocks.9.norm2.weight  |      (384,)            |              |
|      net_t.blocks.9.norm2.bias    |      (384,)            |              |
|     net_t.blocks.9.mlp            |     1.182M             |     0.303G   |
|      net_t.blocks.9.mlp.fc1       |      0.591M            |      0.152G  |
|      net_t.blocks.9.mlp.fc2       |      0.59M             |      0.152G  |
|    net_t.blocks.10                |    1.774M              |    0.456G    |
|     net_t.blocks.10.norm1         |     0.768K             |     0.493M   |
|      net_t.blocks.10.norm1.weight |      (384,)            |              |
|      net_t.blocks.10.norm1.bias   |      (384,)            |              |
|     net_t.blocks.10.attn          |     0.591M             |     0.152G   |
|      net_t.blocks.10.attn.qkv     |      0.444M            |      0.114G  |
|      net_t.blocks.10.attn.proj    |      0.148M            |      37.896M |
|     net_t.blocks.10.norm2         |     0.768K             |     0.493M   |
|      net_t.blocks.10.norm2.weight |      (384,)            |              |
|      net_t.blocks.10.norm2.bias   |      (384,)            |              |
|     net_t.blocks.10.mlp           |     1.182M             |     0.303G   |
|      net_t.blocks.10.mlp.fc1      |      0.591M            |      0.152G  |
|      net_t.blocks.10.mlp.fc2      |      0.59M             |      0.152G  |
|    net_t.blocks.11                |    1.774M              |    0.456G    |
|     net_t.blocks.11.norm1         |     0.768K             |     0.493M   |
|      net_t.blocks.11.norm1.weight |      (384,)            |              |
|      net_t.blocks.11.norm1.bias   |      (384,)            |              |
|     net_t.blocks.11.attn          |     0.591M             |     0.152G   |
|      net_t.blocks.11.attn.qkv     |      0.444M            |      0.114G  |
|      net_t.blocks.11.attn.proj    |      0.148M            |      37.896M |
|     net_t.blocks.11.norm2         |     0.768K             |     0.493M   |
|      net_t.blocks.11.norm2.weight |      (384,)            |              |
|      net_t.blocks.11.norm2.bias   |      (384,)            |              |
|     net_t.blocks.11.mlp           |     1.182M             |     0.303G   |
|      net_t.blocks.11.mlp.fc1      |      0.591M            |      0.152G  |
|      net_t.blocks.11.mlp.fc2      |      0.59M             |      0.152G  |
|   net_t.norm                      |   0.768K               |              |
|    net_t.norm.weight              |    (384,)              |              |
|    net_t.norm.bias                |    (384,)              |              |
|  net_fusion.fc                    |  0.148M                |  37.749M     |
|   net_fusion.fc.weight            |   (384, 384)           |              |
|   net_fusion.fc.bias              |   (384,)               |              |
|  net_s                            |  16.75M                |  4.086G      |
|   net_s.cls_token                 |   (1, 1, 384)          |              |
|   net_s.pos_embed                 |   (1, 256, 384)        |              |
|   net_s.patch_embed.proj          |   0.295M               |              |
|    net_s.patch_embed.proj.weight  |    (384, 3, 16, 16)    |              |
|    net_s.patch_embed.proj.bias    |    (384,)              |              |
|   net_s.blocks                    |   15.97M               |   4.086G     |
|    net_s.blocks.0                 |    1.774M              |    0.454G    |
|     net_s.blocks.0.norm1          |     0.768K             |     0.492M   |
|      net_s.blocks.0.norm1.weight  |      (384,)            |              |
|      net_s.blocks.0.norm1.bias    |      (384,)            |              |
|     net_s.blocks.0.attn           |     0.591M             |     0.151G   |
|      net_s.blocks.0.attn.qkv      |      0.444M            |      0.113G  |
|      net_s.blocks.0.attn.proj     |      0.148M            |      37.749M |
|     net_s.blocks.0.norm2          |     0.768K             |     0.492M   |
|      net_s.blocks.0.norm2.weight  |      (384,)            |              |
|      net_s.blocks.0.norm2.bias    |      (384,)            |              |
|     net_s.blocks.0.mlp            |     1.182M             |     0.302G   |
|      net_s.blocks.0.mlp.fc1       |      0.591M            |      0.151G  |
|      net_s.blocks.0.mlp.fc2       |      0.59M             |      0.151G  |
|    net_s.blocks.1                 |    1.774M              |    0.454G    |
|     net_s.blocks.1.norm1          |     0.768K             |     0.492M   |
|      net_s.blocks.1.norm1.weight  |      (384,)            |              |
|      net_s.blocks.1.norm1.bias    |      (384,)            |              |
|     net_s.blocks.1.attn           |     0.591M             |     0.151G   |
|      net_s.blocks.1.attn.qkv      |      0.444M            |      0.113G  |
|      net_s.blocks.1.attn.proj     |      0.148M            |      37.749M |
|     net_s.blocks.1.norm2          |     0.768K             |     0.492M   |
|      net_s.blocks.1.norm2.weight  |      (384,)            |              |
|      net_s.blocks.1.norm2.bias    |      (384,)            |              |
|     net_s.blocks.1.mlp            |     1.182M             |     0.302G   |
|      net_s.blocks.1.mlp.fc1       |      0.591M            |      0.151G  |
|      net_s.blocks.1.mlp.fc2       |      0.59M             |      0.151G  |
|    net_s.blocks.2                 |    1.774M              |    0.454G    |
|     net_s.blocks.2.norm1          |     0.768K             |     0.492M   |
|      net_s.blocks.2.norm1.weight  |      (384,)            |              |
|      net_s.blocks.2.norm1.bias    |      (384,)            |              |
|     net_s.blocks.2.attn           |     0.591M             |     0.151G   |
|      net_s.blocks.2.attn.qkv      |      0.444M            |      0.113G  |
|      net_s.blocks.2.attn.proj     |      0.148M            |      37.749M |
|     net_s.blocks.2.norm2          |     0.768K             |     0.492M   |
|      net_s.blocks.2.norm2.weight  |      (384,)            |              |
|      net_s.blocks.2.norm2.bias    |      (384,)            |              |
|     net_s.blocks.2.mlp            |     1.182M             |     0.302G   |
|      net_s.blocks.2.mlp.fc1       |      0.591M            |      0.151G  |
|      net_s.blocks.2.mlp.fc2       |      0.59M             |      0.151G  |
|    net_s.blocks.3                 |    1.774M              |    0.454G    |
|     net_s.blocks.3.norm1          |     0.768K             |     0.492M   |
|      net_s.blocks.3.norm1.weight  |      (384,)            |              |
|      net_s.blocks.3.norm1.bias    |      (384,)            |              |
|     net_s.blocks.3.attn           |     0.591M             |     0.151G   |
|      net_s.blocks.3.attn.qkv      |      0.444M            |      0.113G  |
|      net_s.blocks.3.attn.proj     |      0.148M            |      37.749M |
|     net_s.blocks.3.norm2          |     0.768K             |     0.492M   |
|      net_s.blocks.3.norm2.weight  |      (384,)            |              |
|      net_s.blocks.3.norm2.bias    |      (384,)            |              |
|     net_s.blocks.3.mlp            |     1.182M             |     0.302G   |
|      net_s.blocks.3.mlp.fc1       |      0.591M            |      0.151G  |
|      net_s.blocks.3.mlp.fc2       |      0.59M             |      0.151G  |
|    net_s.blocks.4                 |    1.774M              |    0.454G    |
|     net_s.blocks.4.norm1          |     0.768K             |     0.492M   |
|      net_s.blocks.4.norm1.weight  |      (384,)            |              |
|      net_s.blocks.4.norm1.bias    |      (384,)            |              |
|     net_s.blocks.4.attn           |     0.591M             |     0.151G   |
|      net_s.blocks.4.attn.qkv      |      0.444M            |      0.113G  |
|      net_s.blocks.4.attn.proj     |      0.148M            |      37.749M |
|     net_s.blocks.4.norm2          |     0.768K             |     0.492M   |
|      net_s.blocks.4.norm2.weight  |      (384,)            |              |
|      net_s.blocks.4.norm2.bias    |      (384,)            |              |
|     net_s.blocks.4.mlp            |     1.182M             |     0.302G   |
|      net_s.blocks.4.mlp.fc1       |      0.591M            |      0.151G  |
|      net_s.blocks.4.mlp.fc2       |      0.59M             |      0.151G  |
|    net_s.blocks.5                 |    1.774M              |    0.454G    |
|     net_s.blocks.5.norm1          |     0.768K             |     0.492M   |
|      net_s.blocks.5.norm1.weight  |      (384,)            |              |
|      net_s.blocks.5.norm1.bias    |      (384,)            |              |
|     net_s.blocks.5.attn           |     0.591M             |     0.151G   |
|      net_s.blocks.5.attn.qkv      |      0.444M            |      0.113G  |
|      net_s.blocks.5.attn.proj     |      0.148M            |      37.749M |
|     net_s.blocks.5.norm2          |     0.768K             |     0.492M   |
|      net_s.blocks.5.norm2.weight  |      (384,)            |              |
|      net_s.blocks.5.norm2.bias    |      (384,)            |              |
|     net_s.blocks.5.mlp            |     1.182M             |     0.302G   |
|      net_s.blocks.5.mlp.fc1       |      0.591M            |      0.151G  |
|      net_s.blocks.5.mlp.fc2       |      0.59M             |      0.151G  |
|    net_s.blocks.6                 |    1.774M              |    0.454G    |
|     net_s.blocks.6.norm1          |     0.768K             |     0.492M   |
|      net_s.blocks.6.norm1.weight  |      (384,)            |              |
|      net_s.blocks.6.norm1.bias    |      (384,)            |              |
|     net_s.blocks.6.attn           |     0.591M             |     0.151G   |
|      net_s.blocks.6.attn.qkv      |      0.444M            |      0.113G  |
|      net_s.blocks.6.attn.proj     |      0.148M            |      37.749M |
|     net_s.blocks.6.norm2          |     0.768K             |     0.492M   |
|      net_s.blocks.6.norm2.weight  |      (384,)            |              |
|      net_s.blocks.6.norm2.bias    |      (384,)            |              |
|     net_s.blocks.6.mlp            |     1.182M             |     0.302G   |
|      net_s.blocks.6.mlp.fc1       |      0.591M            |      0.151G  |
|      net_s.blocks.6.mlp.fc2       |      0.59M             |      0.151G  |
|    net_s.blocks.7                 |    1.774M              |    0.454G    |
|     net_s.blocks.7.norm1          |     0.768K             |     0.492M   |
|      net_s.blocks.7.norm1.weight  |      (384,)            |              |
|      net_s.blocks.7.norm1.bias    |      (384,)            |              |
|     net_s.blocks.7.attn           |     0.591M             |     0.151G   |
|      net_s.blocks.7.attn.qkv      |      0.444M            |      0.113G  |
|      net_s.blocks.7.attn.proj     |      0.148M            |      37.749M |
|     net_s.blocks.7.norm2          |     0.768K             |     0.492M   |
|      net_s.blocks.7.norm2.weight  |      (384,)            |              |
|      net_s.blocks.7.norm2.bias    |      (384,)            |              |
|     net_s.blocks.7.mlp            |     1.182M             |     0.302G   |
|      net_s.blocks.7.mlp.fc1       |      0.591M            |      0.151G  |
|      net_s.blocks.7.mlp.fc2       |      0.59M             |      0.151G  |
|    net_s.blocks.8                 |    1.774M              |    0.454G    |
|     net_s.blocks.8.norm1          |     0.768K             |     0.492M   |
|      net_s.blocks.8.norm1.weight  |      (384,)            |              |
|      net_s.blocks.8.norm1.bias    |      (384,)            |              |
|     net_s.blocks.8.attn           |     0.591M             |     0.151G   |
|      net_s.blocks.8.attn.qkv      |      0.444M            |      0.113G  |
|      net_s.blocks.8.attn.proj     |      0.148M            |      37.749M |
|     net_s.blocks.8.norm2          |     0.768K             |     0.492M   |
|      net_s.blocks.8.norm2.weight  |      (384,)            |              |
|      net_s.blocks.8.norm2.bias    |      (384,)            |              |
|     net_s.blocks.8.mlp            |     1.182M             |     0.302G   |
|      net_s.blocks.8.mlp.fc1       |      0.591M            |      0.151G  |
|      net_s.blocks.8.mlp.fc2       |      0.59M             |      0.151G  |
|   net_s.norm                      |   0.768K               |              |
|    net_s.norm.weight              |    (384,)              |              |
|    net_s.norm.bias                |    (384,)              |              |
|   net_s.head                      |   0.385M               |              |
|    net_s.head.weight              |    (1000, 384)         |              |
|    net_s.head.bias                |    (1000,)             |              |
-------------------------------------------------------------------------------
2025-12-09 21:47:40,945 - ==> Creating optimizer
2025-12-09 21:47:40,947 - ==> Loading dataset: DefaultAD
2025-12-09 21:47:40,983 - ==> ********** cfg ********** 
fvcore_is                            : True                                
fvcore_b                             : 1                                   
fvcore_c                             : 3                                   
epoch_full                           : 100                                 
metrics                              : ['mAUROC_sp_max', 'mAP_sp_max', 'mF1_max_sp_max', 'mAUPRO_px', 'mAUROC_px', 'mAP_px', 'mF1_max_px', 'mF1_px_0.2_0.8_0.1', 'mAcc_px_0.2_0.8_0.1', 'mIoU_px_0.2_0.8_0.1', 'mIoU_max_px']
use_adeval                           : True                                
evaluator.kwargs                     : {'metrics': ['mAUROC_sp_max', 'mAP_sp_max', 'mF1_max_sp_max', 'mAUPRO_px', 'mAUROC_px', 'mAP_px', 'mF1_max_px', 'mF1_px_0.2_0.8_0.1', 'mAcc_px_0.2_0.8_0.1', 'mIoU_px_0.2_0.8_0.1', 'mIoU_max_px'], 'pooling_ks': [16, 16], 'max_step_aupro': 100}
vis                                  : False                               
vis_dir                              : None                                
optim.lr                             : 0.0001                              
optim.kwargs                         : {'name': 'adamw', 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0001, 'amsgrad': False}
trainer.name                         : ViTADTrainer                        
trainer.checkpoint                   : runs                                
trainer.logdir_sub                   :                                     
trainer.resume_dir                   :                                     
trainer.cuda_deterministic           : False                               
trainer.epoch_full                   : 100                                 
trainer.scheduler_kwargs             : {'name': 'step', 'lr_noise': None, 'noise_pct': 0.67, 'noise_std': 1.0, 'noise_seed': 42, 'lr_min': 1e-06, 'warmup_lr': 1.0000000000000001e-07, 'warmup_iters': -1, 'cooldown_iters': 0, 'warmup_epochs': 0, 'cooldown_epochs': 0, 'use_iters': True, 'patience_iters': 0, 'patience_epochs': 0, 'decay_iters': 0, 'decay_epochs': 80, 'cycle_decay': 0.1, 'decay_rate': 0.1}
trainer.mixup_kwargs                 : {'mixup_alpha': 0.8, 'cutmix_alpha': 1.0, 'cutmix_minmax': None, 'prob': 0.0, 'switch_prob': 0.5, 'mode': 'batch', 'correct_lam': True, 'label_smoothing': 0.1}
trainer.test_start_epoch             : 100                                 
trainer.test_per_epoch               : 10                                  
trainer.find_unused_parameters       : False                               
trainer.sync_BN                      : apex                                
trainer.dist_BN                      :                                     
trainer.scaler                       : none                                
trainer.data.batch_size              : 8                                   
trainer.data.batch_size_per_gpu      : 8                                   
trainer.data.batch_size_test         : 8                                   
trainer.data.batch_size_per_gpu_test : 8                                   
trainer.data.num_workers_per_gpu     : 4                                   
trainer.data.drop_last               : True                                
trainer.data.pin_memory              : True                                
trainer.data.persistent_workers      : False                               
trainer.data.num_workers             : 4                                   
trainer.iter                         : 0                                   
trainer.epoch                        : 0                                   
trainer.iter_full                    : 97600                               
trainer.metric_recorder              : {'mAUROC_sp_max_glass-insulator': [], 'mAP_sp_max_glass-insulator': [], 'mF1_max_sp_max_glass-insulator': [], 'mAUPRO_px_glass-insulator': [], 'mAUROC_px_glass-insulator': [], 'mAP_px_glass-insulator': [], 'mF1_max_px_glass-insulator': [], 'mF1_px_0.2_0.8_0.1_glass-insulator': [], 'mAcc_px_0.2_0.8_0.1_glass-insulator': [], 'mIoU_px_0.2_0.8_0.1_glass-insulator': [], 'mIoU_max_px_glass-insulator': [], 'mAUROC_sp_max_lightning-rod-suspension': [], 'mAP_sp_max_lightning-rod-suspension': [], 'mF1_max_sp_max_lightning-rod-suspension': [], 'mAUPRO_px_lightning-rod-suspension': [], 'mAUROC_px_lightning-rod-suspension': [], 'mAP_px_lightning-rod-suspension': [], 'mF1_max_px_lightning-rod-suspension': [], 'mF1_px_0.2_0.8_0.1_lightning-rod-suspension': [], 'mAcc_px_0.2_0.8_0.1_lightning-rod-suspension': [], 'mIoU_px_0.2_0.8_0.1_lightning-rod-suspension': [], 'mIoU_max_px_lightning-rod-suspension': [], 'mAUROC_sp_max_polymer-insulator-upper-shackle': [], 'mAP_sp_max_polymer-insulator-upper-shackle': [], 'mF1_max_sp_max_polymer-insulator-upper-shackle': [], 'mAUPRO_px_polymer-insulator-upper-shackle': [], 'mAUROC_px_polymer-insulator-upper-shackle': [], 'mAP_px_polymer-insulator-upper-shackle': [], 'mF1_max_px_polymer-insulator-upper-shackle': [], 'mF1_px_0.2_0.8_0.1_polymer-insulator-upper-shackle': [], 'mAcc_px_0.2_0.8_0.1_polymer-insulator-upper-shackle': [], 'mIoU_px_0.2_0.8_0.1_polymer-insulator-upper-shackle': [], 'mIoU_max_px_polymer-insulator-upper-shackle': [], 'mAUROC_sp_max_vari-grip': [], 'mAP_sp_max_vari-grip': [], 'mF1_max_sp_max_vari-grip': [], 'mAUPRO_px_vari-grip': [], 'mAUROC_px_vari-grip': [], 'mAP_px_vari-grip': [], 'mF1_max_px_vari-grip': [], 'mF1_px_0.2_0.8_0.1_vari-grip': [], 'mAcc_px_0.2_0.8_0.1_vari-grip': [], 'mIoU_px_0.2_0.8_0.1_vari-grip': [], 'mIoU_max_px_vari-grip': [], 'mAUROC_sp_max_yoke-suspension': [], 'mAUROC_sp_max_Avg': [], 'mAP_sp_max_yoke-suspension': [], 'mAP_sp_max_Avg': [], 'mF1_max_sp_max_yoke-suspension': [], 'mF1_max_sp_max_Avg': [], 'mAUPRO_px_yoke-suspension': [], 'mAUPRO_px_Avg': [], 'mAUROC_px_yoke-suspension': [], 'mAUROC_px_Avg': [], 'mAP_px_yoke-suspension': [], 'mAP_px_Avg': [], 'mF1_max_px_yoke-suspension': [], 'mF1_max_px_Avg': [], 'mF1_px_0.2_0.8_0.1_yoke-suspension': [], 'mF1_px_0.2_0.8_0.1_Avg': [], 'mAcc_px_0.2_0.8_0.1_yoke-suspension': [], 'mAcc_px_0.2_0.8_0.1_Avg': [], 'mIoU_px_0.2_0.8_0.1_yoke-suspension': [], 'mIoU_px_0.2_0.8_0.1_Avg': [], 'mIoU_max_px_yoke-suspension': [], 'mIoU_max_px_Avg': []}
loss.loss_terms                      : [{'type': 'CosLoss', 'name': 'cos', 'avg': False, 'lam': 1.0}]
loss.clip_grad                       : 5.0                                 
loss.create_graph                    : False                               
loss.retain_graph                    : False                               
adv                                  : False                               
logging.log_terms_train              : [{'name': 'batch_t', 'fmt': ':>5.3f', 'add_name': 'avg'}, {'name': 'data_t', 'fmt': ':>5.3f'}, {'name': 'optim_t', 'fmt': ':>5.3f'}, {'name': 'lr', 'fmt': ':>7.6f'}, {'name': 'cos', 'suffixes': [''], 'fmt': ':>5.3f', 'add_name': 'avg'}]
logging.log_terms_test               : [{'name': 'batch_t', 'fmt': ':>5.3f', 'add_name': 'avg'}, {'name': 'cos', 'suffixes': [''], 'fmt': ':>5.3f', 'add_name': 'avg'}]
logging.train_reset_log_per          : 50                                  
logging.train_log_per                : 50                                  
logging.test_log_per                 : 50                                  
data.sampler                         : naive                               
data.loader_type                     : pil                                 
data.loader_type_target              : pil_L                               
data.type                            : DefaultAD                           
data.root                            : data/insplad-seg                    
data.meta                            : meta.json                           
data.cls_names                       : []                                  
data.train_transforms                : [{'type': 'Resize', 'size': (256, 256), 'interpolation': <InterpolationMode.BILINEAR: 'bilinear'>}, {'type': 'CenterCrop', 'size': (256, 256)}, {'type': 'ToTensor'}, {'type': 'Normalize', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'inplace': True}]
data.test_transforms                 : [{'type': 'Resize', 'size': (256, 256), 'interpolation': <InterpolationMode.BILINEAR: 'bilinear'>}, {'type': 'CenterCrop', 'size': (256, 256)}, {'type': 'ToTensor'}, {'type': 'Normalize', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'inplace': True}]
data.target_transforms               : [{'type': 'Resize', 'size': (256, 256), 'interpolation': <InterpolationMode.BILINEAR: 'bilinear'>}, {'type': 'CenterCrop', 'size': (256, 256)}, {'type': 'ToTensor'}]
data.train_size                      : 976                                 
data.test_size                       : 321                                 
data.train_length                    : 7812                                
data.test_length                     : 2565                                
model_t.name                         : vit_small_patch16_224_dino          
model_t.kwargs                       : {'pretrained': True, 'checkpoint_path': '', 'pretrained_strict': False, 'strict': True, 'img_size': 256, 'teachers': [3, 6, 9], 'neck': [12]}
model_f.name                         : fusion                              
model_f.kwargs                       : {'pretrained': False, 'checkpoint_path': '', 'strict': False, 'dim': 384, 'mul': 1}
model_s.name                         : de_vit_small_patch16_224_dino       
model_s.kwargs                       : {'pretrained': False, 'checkpoint_path': '', 'strict': False, 'img_size': 256, 'students': [3, 6, 9], 'depth': 9}
model.name                           : vitad                               
model.kwargs                         : {'pretrained': False, 'checkpoint_path': '', 'strict': True, 'model_t': Namespace(name='vit_small_patch16_224_dino', kwargs={'pretrained': True, 'checkpoint_path': '', 'pretrained_strict': False, 'strict': True, 'img_size': 256, 'teachers': [3, 6, 9], 'neck': [12]}), 'model_f': Namespace(name='fusion', kwargs={'pretrained': False, 'checkpoint_path': '', 'strict': False, 'dim': 384, 'mul': 1}), 'model_s': Namespace(name='de_vit_small_patch16_224_dino', kwargs={'pretrained': False, 'checkpoint_path': '', 'strict': False, 'img_size': 256, 'students': [3, 6, 9], 'depth': 9})}
seed                                 : 42                                  
size                                 : 256                                 
warmup_epochs                        : 0                                   
test_start_epoch                     : 100                                 
test_per_epoch                       : 10                                  
batch_train                          : 8                                   
batch_test_per                       : 8                                   
lr                                   : 0.0001                              
weight_decay                         : 0.0001                              
cfg_path                             : configs.vitad.vitad_insplad         
mode                                 : train                               
sleep                                : -1                                  
memory                               : -1                                  
dist_url                             : env://                              
logger_rank                          : 0                                   
opts                                 : []                                  
command                              : python3 -m torch.distributed.launch --nproc_per_node=$nproc_per_node --nnodes=$nnodes --node_rank=$node_rank --master_addr=$master_addr --master_port=$master_port --use_env run.py -c configs.vitad.vitad_insplad -m train --sleep -1 --memory -1 --dist_url env:// --logger_rank 0 
task_start_time                      : 114129.8711433                      
dist                                 : False                               
world_size                           : 1                                   
rank                                 : 0                                   
local_rank                           : 0                                   
ngpus_per_node                       : 1                                   
nnodes                               : 1                                   
master                               : True                                
logdir                               : runs/ViTADTrainer_configs_vitad_vitad_insplad_20251209-214738
logger.filters                       : []                                  
logger.name                          : root                                
logger.level                         : 20                                  
logger.parent                        : None                                
logger.propagate                     : True                                
logger.disabled                      : False                               
logdir_train                         : runs/ViTADTrainer_configs_vitad_vitad_insplad_20251209-214738/show_train
logdir_test                          : runs/ViTADTrainer_configs_vitad_vitad_insplad_20251209-214738/show_test
2025-12-09 21:47:40,983 - ==> Starting training with 1 nodes x 1 GPUs
2025-12-09 21:48:01,220 - Train: 0.05% [50/97600]  [0.1/100.0] [batch_t 0.067 (0.078)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 1.222 (1.571)]
2025-12-09 21:48:04,517 - Train: 0.10% [100/97600]  [0.1/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.906 (1.041)]
2025-12-09 21:48:07,772 - Train: 0.15% [150/97600]  [0.2/100.0] [batch_t 0.065 (0.065)] [data_t 0.001] [optim_t 0.064] [lr 0.000100] [cos 0.816 (0.851)]
2025-12-09 21:48:11,029 - Train: 0.20% [200/97600]  [0.2/100.0] [batch_t 0.065 (0.065)] [data_t 0.001] [optim_t 0.064] [lr 0.000100] [cos 0.683 (0.759)]
2025-12-09 21:48:14,285 - Train: 0.26% [250/97600]  [0.3/100.0] [batch_t 0.065 (0.065)] [data_t 0.001] [optim_t 0.064] [lr 0.000100] [cos 0.660 (0.699)]
2025-12-09 21:48:17,545 - Train: 0.31% [300/97600]  [0.3/100.0] [batch_t 0.065 (0.065)] [data_t 0.001] [optim_t 0.064] [lr 0.000100] [cos 0.667 (0.660)]
2025-12-09 21:48:20,795 - Train: 0.36% [350/97600]  [0.4/100.0] [batch_t 0.065 (0.065)] [data_t 0.001] [optim_t 0.064] [lr 0.000100] [cos 0.615 (0.625)]
2025-12-09 21:48:24,068 - Train: 0.41% [400/97600]  [0.4/100.0] [batch_t 0.065 (0.065)] [data_t 0.001] [optim_t 0.064] [lr 0.000100] [cos 0.596 (0.597)]
2025-12-09 21:48:27,336 - Train: 0.46% [450/97600]  [0.5/100.0] [batch_t 0.065 (0.065)] [data_t 0.001] [optim_t 0.064] [lr 0.000100] [cos 0.572 (0.576)]
2025-12-09 21:48:30,613 - Train: 0.51% [500/97600]  [0.5/100.0] [batch_t 0.066 (0.065)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.556 (0.552)]
2025-12-09 21:48:33,884 - Train: 0.56% [550/97600]  [0.6/100.0] [batch_t 0.065 (0.065)] [data_t 0.001] [optim_t 0.064] [lr 0.000100] [cos 0.590 (0.542)]
2025-12-09 21:48:37,165 - Train: 0.61% [600/97600]  [0.6/100.0] [batch_t 0.064 (0.066)] [data_t 0.001] [optim_t 0.063] [lr 0.000100] [cos 0.536 (0.517)]
2025-12-09 21:48:40,441 - Train: 0.67% [650/97600]  [0.7/100.0] [batch_t 0.066 (0.065)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.522 (0.511)]
2025-12-09 21:48:43,722 - Train: 0.72% [700/97600]  [0.7/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.528 (0.499)]
2025-12-09 21:48:46,997 - Train: 0.77% [750/97600]  [0.8/100.0] [batch_t 0.066 (0.065)] [data_t 0.001] [optim_t 0.064] [lr 0.000100] [cos 0.469 (0.486)]
2025-12-09 21:48:50,280 - Train: 0.82% [800/97600]  [0.8/100.0] [batch_t 0.065 (0.066)] [data_t 0.001] [optim_t 0.064] [lr 0.000100] [cos 0.442 (0.483)]
2025-12-09 21:48:53,564 - Train: 0.87% [850/97600]  [0.9/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.469 (0.476)]
2025-12-09 21:48:56,852 - Train: 0.92% [900/97600]  [0.9/100.0] [batch_t 0.065 (0.066)] [data_t 0.001] [optim_t 0.064] [lr 0.000100] [cos 0.450 (0.463)]
2025-12-09 21:49:00,137 - Train: 0.97% [950/97600]  [1.0/100.0] [batch_t 0.065 (0.066)] [data_t 0.001] [optim_t 0.064] [lr 0.000100] [cos 0.437 (0.456)]
2025-12-09 21:49:01,848 - ==> Total time: 0:01:23	 Eta: 2:17:05 	Logged in 'runs/ViTADTrainer_configs_vitad_vitad_insplad_20251209-214738'
2025-12-09 21:49:21,802 - Train: 1.02% [1000/97600]  [1.0/100.0] [batch_t 0.070 (0.081)] [data_t 0.001] [optim_t 0.069] [lr 0.000100] [cos 0.441 (0.450)]
2025-12-09 21:49:25,225 - Train: 1.08% [1050/97600]  [1.1/100.0] [batch_t 0.068 (0.068)] [data_t 0.001] [optim_t 0.067] [lr 0.000100] [cos 0.459 (0.441)]
2025-12-09 21:49:28,548 - Train: 1.13% [1100/97600]  [1.1/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.417 (0.437)]
2025-12-09 21:49:31,852 - Train: 1.18% [1150/97600]  [1.2/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.424 (0.427)]
2025-12-09 21:49:35,142 - Train: 1.23% [1200/97600]  [1.2/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.416 (0.425)]
2025-12-09 21:49:38,451 - Train: 1.28% [1250/97600]  [1.3/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.405 (0.418)]
2025-12-09 21:49:41,744 - Train: 1.33% [1300/97600]  [1.3/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.403 (0.419)]
2025-12-09 21:49:45,043 - Train: 1.38% [1350/97600]  [1.4/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.389 (0.413)]
2025-12-09 21:49:48,347 - Train: 1.43% [1400/97600]  [1.4/100.0] [batch_t 0.067 (0.066)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.406 (0.404)]
2025-12-09 21:49:51,652 - Train: 1.49% [1450/97600]  [1.5/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.383 (0.398)]
2025-12-09 21:49:54,959 - Train: 1.54% [1500/97600]  [1.5/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.392 (0.400)]
2025-12-09 21:49:58,267 - Train: 1.59% [1550/97600]  [1.6/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.417 (0.395)]
2025-12-09 21:50:01,580 - Train: 1.64% [1600/97600]  [1.6/100.0] [batch_t 0.065 (0.066)] [data_t 0.001] [optim_t 0.064] [lr 0.000100] [cos 0.402 (0.390)]
2025-12-09 21:50:04,883 - Train: 1.69% [1650/97600]  [1.7/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.377 (0.387)]
2025-12-09 21:50:08,195 - Train: 1.74% [1700/97600]  [1.7/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.387 (0.381)]
2025-12-09 21:50:11,516 - Train: 1.79% [1750/97600]  [1.8/100.0] [batch_t 0.067 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.337 (0.374)]
2025-12-09 21:50:14,851 - Train: 1.84% [1800/97600]  [1.8/100.0] [batch_t 0.066 (0.067)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.436 (0.376)]
2025-12-09 21:50:18,178 - Train: 1.90% [1850/97600]  [1.9/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.383 (0.380)]
2025-12-09 21:50:21,503 - Train: 1.95% [1900/97600]  [1.9/100.0] [batch_t 0.067 (0.066)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.397 (0.371)]
2025-12-09 21:50:24,827 - Train: 2.00% [1950/97600]  [2.0/100.0] [batch_t 0.065 (0.066)] [data_t 0.001] [optim_t 0.064] [lr 0.000100] [cos 0.368 (0.370)]
2025-12-09 21:50:24,963 - ==> Total time: 0:02:46	 Eta: 2:15:43 	Logged in 'runs/ViTADTrainer_configs_vitad_vitad_insplad_20251209-214738'
2025-12-09 21:50:46,034 - Train: 2.05% [2000/97600]  [2.0/100.0] [batch_t 0.067 (0.076)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.351 (0.366)]
2025-12-09 21:50:49,418 - Train: 2.10% [2050/97600]  [2.1/100.0] [batch_t 0.068 (0.068)] [data_t 0.001] [optim_t 0.067] [lr 0.000100] [cos 0.365 (0.358)]
2025-12-09 21:50:52,756 - Train: 2.15% [2100/97600]  [2.2/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.371 (0.358)]
2025-12-09 21:50:56,063 - Train: 2.20% [2150/97600]  [2.2/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.351 (0.358)]
2025-12-09 21:50:59,365 - Train: 2.25% [2200/97600]  [2.3/100.0] [batch_t 0.065 (0.066)] [data_t 0.001] [optim_t 0.064] [lr 0.000100] [cos 0.353 (0.353)]
2025-12-09 21:51:02,669 - Train: 2.31% [2250/97600]  [2.3/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.378 (0.353)]
2025-12-09 21:51:05,975 - Train: 2.36% [2300/97600]  [2.4/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.350 (0.348)]
2025-12-09 21:51:09,289 - Train: 2.41% [2350/97600]  [2.4/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.341 (0.345)]
2025-12-09 21:51:12,599 - Train: 2.46% [2400/97600]  [2.5/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.334 (0.344)]
2025-12-09 21:51:15,907 - Train: 2.51% [2450/97600]  [2.5/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.334 (0.336)]
2025-12-09 21:51:19,221 - Train: 2.56% [2500/97600]  [2.6/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.324 (0.342)]
2025-12-09 21:51:22,530 - Train: 2.61% [2550/97600]  [2.6/100.0] [batch_t 0.065 (0.066)] [data_t 0.001] [optim_t 0.064] [lr 0.000100] [cos 0.327 (0.337)]
2025-12-09 21:51:25,847 - Train: 2.66% [2600/97600]  [2.7/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.320 (0.333)]
2025-12-09 21:51:29,166 - Train: 2.72% [2650/97600]  [2.7/100.0] [batch_t 0.067 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.312 (0.337)]
2025-12-09 21:51:32,481 - Train: 2.77% [2700/97600]  [2.8/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.309 (0.329)]
2025-12-09 21:51:35,807 - Train: 2.82% [2750/97600]  [2.8/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.325 (0.332)]
2025-12-09 21:51:39,130 - Train: 2.87% [2800/97600]  [2.9/100.0] [batch_t 0.065 (0.066)] [data_t 0.001] [optim_t 0.064] [lr 0.000100] [cos 0.305 (0.326)]
2025-12-09 21:51:42,443 - Train: 2.92% [2850/97600]  [2.9/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.327 (0.329)]
2025-12-09 21:51:45,765 - Train: 2.97% [2900/97600]  [3.0/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.323 (0.322)]
2025-12-09 21:51:47,627 - ==> Total time: 0:04:08	 Eta: 2:14:06 	Logged in 'runs/ViTADTrainer_configs_vitad_vitad_insplad_20251209-214738'
2025-12-09 21:52:11,403 - Train: 3.02% [2950/97600]  [3.0/100.0] [batch_t 0.070 (0.084)] [data_t 0.001] [optim_t 0.069] [lr 0.000100] [cos 0.297 (0.316)]
2025-12-09 21:52:14,839 - Train: 3.07% [3000/97600]  [3.1/100.0] [batch_t 0.068 (0.069)] [data_t 0.001] [optim_t 0.067] [lr 0.000100] [cos 0.327 (0.320)]
2025-12-09 21:52:18,204 - Train: 3.12% [3050/97600]  [3.1/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.326 (0.320)]
2025-12-09 21:52:21,617 - Train: 3.18% [3100/97600]  [3.2/100.0] [batch_t 0.068 (0.068)] [data_t 0.001] [optim_t 0.067] [lr 0.000100] [cos 0.345 (0.316)]
2025-12-09 21:52:24,974 - Train: 3.23% [3150/97600]  [3.2/100.0] [batch_t 0.066 (0.067)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.318 (0.319)]
2025-12-09 21:52:28,366 - Train: 3.28% [3200/97600]  [3.3/100.0] [batch_t 0.071 (0.068)] [data_t 0.001] [optim_t 0.070] [lr 0.000100] [cos 0.309 (0.312)]
2025-12-09 21:52:31,696 - Train: 3.33% [3250/97600]  [3.3/100.0] [batch_t 0.065 (0.066)] [data_t 0.001] [optim_t 0.064] [lr 0.000100] [cos 0.313 (0.314)]
2025-12-09 21:52:35,095 - Train: 3.38% [3300/97600]  [3.4/100.0] [batch_t 0.067 (0.068)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.308 (0.311)]
2025-12-09 21:52:38,467 - Train: 3.43% [3350/97600]  [3.4/100.0] [batch_t 0.066 (0.067)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.294 (0.307)]
2025-12-09 21:52:41,829 - Train: 3.48% [3400/97600]  [3.5/100.0] [batch_t 0.066 (0.067)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.305 (0.310)]
2025-12-09 21:52:45,205 - Train: 3.53% [3450/97600]  [3.5/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.364 (0.312)]
2025-12-09 21:52:48,593 - Train: 3.59% [3500/97600]  [3.6/100.0] [batch_t 0.067 (0.068)] [data_t 0.002] [optim_t 0.066] [lr 0.000100] [cos 0.304 (0.307)]
2025-12-09 21:52:51,949 - Train: 3.64% [3550/97600]  [3.6/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.291 (0.305)]
2025-12-09 21:52:55,317 - Train: 3.69% [3600/97600]  [3.7/100.0] [batch_t 0.068 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.310 (0.302)]
2025-12-09 21:52:58,685 - Train: 3.74% [3650/97600]  [3.7/100.0] [batch_t 0.069 (0.067)] [data_t 0.001] [optim_t 0.068] [lr 0.000100] [cos 0.312 (0.309)]
2025-12-09 21:53:02,052 - Train: 3.79% [3700/97600]  [3.8/100.0] [batch_t 0.066 (0.067)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.300 (0.305)]
2025-12-09 21:53:05,428 - Train: 3.84% [3750/97600]  [3.8/100.0] [batch_t 0.066 (0.067)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.297 (0.302)]
2025-12-09 21:53:08,835 - Train: 3.89% [3800/97600]  [3.9/100.0] [batch_t 0.068 (0.068)] [data_t 0.001] [optim_t 0.067] [lr 0.000100] [cos 0.277 (0.302)]
2025-12-09 21:53:12,246 - Train: 3.94% [3850/97600]  [3.9/100.0] [batch_t 0.067 (0.068)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.318 (0.294)]
2025-12-09 21:53:15,625 - Train: 4.00% [3900/97600]  [4.0/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.302 (0.294)]
2025-12-09 21:53:15,897 - ==> Total time: 0:05:37	 Eta: 2:14:51 	Logged in 'runs/ViTADTrainer_configs_vitad_vitad_insplad_20251209-214738'
2025-12-09 21:53:40,461 - Train: 4.05% [3950/97600]  [4.0/100.0] [batch_t 0.069 (0.076)] [data_t 0.001] [optim_t 0.068] [lr 0.000100] [cos 0.302 (0.296)]
2025-12-09 21:53:43,860 - Train: 4.10% [4000/97600]  [4.1/100.0] [batch_t 0.067 (0.068)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.292 (0.293)]
2025-12-09 21:53:47,223 - Train: 4.15% [4050/97600]  [4.1/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.308 (0.295)]
2025-12-09 21:53:50,579 - Train: 4.20% [4100/97600]  [4.2/100.0] [batch_t 0.066 (0.067)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.259 (0.290)]
2025-12-09 21:53:53,980 - Train: 4.25% [4150/97600]  [4.3/100.0] [batch_t 0.075 (0.068)] [data_t 0.001] [optim_t 0.073] [lr 0.000100] [cos 0.292 (0.292)]
2025-12-09 21:53:57,338 - Train: 4.30% [4200/97600]  [4.3/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.319 (0.292)]
2025-12-09 21:54:00,705 - Train: 4.35% [4250/97600]  [4.4/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.291 (0.286)]
2025-12-09 21:54:04,063 - Train: 4.41% [4300/97600]  [4.4/100.0] [batch_t 0.066 (0.067)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.292 (0.285)]
2025-12-09 21:54:07,428 - Train: 4.46% [4350/97600]  [4.5/100.0] [batch_t 0.070 (0.067)] [data_t 0.001] [optim_t 0.069] [lr 0.000100] [cos 0.280 (0.286)]
2025-12-09 21:54:10,777 - Train: 4.51% [4400/97600]  [4.5/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.287 (0.285)]
2025-12-09 21:54:14,137 - Train: 4.56% [4450/97600]  [4.6/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.321 (0.289)]
2025-12-09 21:54:17,506 - Train: 4.61% [4500/97600]  [4.6/100.0] [batch_t 0.066 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.281 (0.286)]
2025-12-09 21:54:20,874 - Train: 4.66% [4550/97600]  [4.7/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.296 (0.284)]
2025-12-09 21:54:24,246 - Train: 4.71% [4600/97600]  [4.7/100.0] [batch_t 0.068 (0.067)] [data_t 0.001] [optim_t 0.067] [lr 0.000100] [cos 0.270 (0.280)]
2025-12-09 21:54:27,613 - Train: 4.76% [4650/97600]  [4.8/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.300 (0.280)]
2025-12-09 21:54:30,983 - Train: 4.82% [4700/97600]  [4.8/100.0] [batch_t 0.066 (0.067)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.291 (0.279)]
2025-12-09 21:54:34,389 - Train: 4.87% [4750/97600]  [4.9/100.0] [batch_t 0.067 (0.068)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.276 (0.279)]
2025-12-09 21:54:37,775 - Train: 4.92% [4800/97600]  [4.9/100.0] [batch_t 0.067 (0.068)] [data_t 0.002] [optim_t 0.065] [lr 0.000100] [cos 0.256 (0.274)]
2025-12-09 21:54:41,158 - Train: 4.97% [4850/97600]  [5.0/100.0] [batch_t 0.067 (0.068)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.291 (0.276)]
2025-12-09 21:54:43,188 - ==> Total time: 0:07:04	 Eta: 2:14:24 	Logged in 'runs/ViTADTrainer_configs_vitad_vitad_insplad_20251209-214738'
2025-12-09 21:55:05,822 - Train: 5.02% [4900/97600]  [5.0/100.0] [batch_t 0.070 (0.081)] [data_t 0.001] [optim_t 0.069] [lr 0.000100] [cos 0.259 (0.277)]
2025-12-09 21:55:09,273 - Train: 5.07% [4950/97600]  [5.1/100.0] [batch_t 0.068 (0.069)] [data_t 0.001] [optim_t 0.067] [lr 0.000100] [cos 0.289 (0.273)]
2025-12-09 21:55:12,663 - Train: 5.12% [5000/97600]  [5.1/100.0] [batch_t 0.069 (0.068)] [data_t 0.001] [optim_t 0.068] [lr 0.000100] [cos 0.270 (0.271)]
2025-12-09 21:55:16,047 - Train: 5.17% [5050/97600]  [5.2/100.0] [batch_t 0.067 (0.068)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.274 (0.272)]
2025-12-09 21:55:19,481 - Train: 5.23% [5100/97600]  [5.2/100.0] [batch_t 0.066 (0.069)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.284 (0.274)]
2025-12-09 21:55:22,848 - Train: 5.28% [5150/97600]  [5.3/100.0] [batch_t 0.069 (0.067)] [data_t 0.001] [optim_t 0.068] [lr 0.000100] [cos 0.288 (0.276)]
2025-12-09 21:55:26,213 - Train: 5.33% [5200/97600]  [5.3/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.275 (0.272)]
2025-12-09 21:55:29,594 - Train: 5.38% [5250/97600]  [5.4/100.0] [batch_t 0.070 (0.067)] [data_t 0.001] [optim_t 0.069] [lr 0.000100] [cos 0.266 (0.269)]
2025-12-09 21:55:32,959 - Train: 5.43% [5300/97600]  [5.4/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.314 (0.271)]
2025-12-09 21:55:36,341 - Train: 5.48% [5350/97600]  [5.5/100.0] [batch_t 0.068 (0.068)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.271 (0.268)]
2025-12-09 21:55:39,714 - Train: 5.53% [5400/97600]  [5.5/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.262 (0.268)]
2025-12-09 21:55:43,091 - Train: 5.58% [5450/97600]  [5.6/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.248 (0.267)]
2025-12-09 21:55:46,463 - Train: 5.64% [5500/97600]  [5.6/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.284 (0.266)]
2025-12-09 21:55:49,833 - Train: 5.69% [5550/97600]  [5.7/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.276 (0.263)]
2025-12-09 21:55:53,227 - Train: 5.74% [5600/97600]  [5.7/100.0] [batch_t 0.066 (0.068)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.267 (0.264)]
2025-12-09 21:55:56,642 - Train: 5.79% [5650/97600]  [5.8/100.0] [batch_t 0.067 (0.068)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.248 (0.268)]
2025-12-09 21:56:00,039 - Train: 5.84% [5700/97600]  [5.8/100.0] [batch_t 0.067 (0.068)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.265 (0.268)]
2025-12-09 21:56:03,417 - Train: 5.89% [5750/97600]  [5.9/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.259 (0.266)]
2025-12-09 21:56:06,805 - Train: 5.94% [5800/97600]  [5.9/100.0] [batch_t 0.067 (0.068)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.267 (0.263)]
2025-12-09 21:56:10,227 - Train: 5.99% [5850/97600]  [6.0/100.0] [batch_t 0.068 (0.068)] [data_t 0.001] [optim_t 0.068] [lr 0.000100] [cos 0.258 (0.265)]
2025-12-09 21:56:10,628 - ==> Total time: 0:08:31	 Eta: 2:13:39 	Logged in 'runs/ViTADTrainer_configs_vitad_vitad_insplad_20251209-214738'
2025-12-09 21:56:34,890 - Train: 6.05% [5900/97600]  [6.0/100.0] [batch_t 0.070 (0.077)] [data_t 0.001] [optim_t 0.069] [lr 0.000100] [cos 0.265 (0.259)]
2025-12-09 21:56:38,292 - Train: 6.10% [5950/97600]  [6.1/100.0] [batch_t 0.068 (0.068)] [data_t 0.001] [optim_t 0.067] [lr 0.000100] [cos 0.255 (0.258)]
2025-12-09 21:56:41,635 - Train: 6.15% [6000/97600]  [6.1/100.0] [batch_t 0.068 (0.067)] [data_t 0.001] [optim_t 0.067] [lr 0.000100] [cos 0.276 (0.258)]
2025-12-09 21:56:44,958 - Train: 6.20% [6050/97600]  [6.2/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.257 (0.261)]
2025-12-09 21:56:48,275 - Train: 6.25% [6100/97600]  [6.2/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.255 (0.260)]
2025-12-09 21:56:51,600 - Train: 6.30% [6150/97600]  [6.3/100.0] [batch_t 0.067 (0.066)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.253 (0.258)]
2025-12-09 21:56:54,929 - Train: 6.35% [6200/97600]  [6.4/100.0] [batch_t 0.065 (0.066)] [data_t 0.001] [optim_t 0.064] [lr 0.000100] [cos 0.258 (0.257)]
2025-12-09 21:56:58,257 - Train: 6.40% [6250/97600]  [6.4/100.0] [batch_t 0.067 (0.066)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.258 (0.260)]
2025-12-09 21:57:01,585 - Train: 6.45% [6300/97600]  [6.5/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.246 (0.259)]
2025-12-09 21:57:04,920 - Train: 6.51% [6350/97600]  [6.5/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.242 (0.255)]
2025-12-09 21:57:08,252 - Train: 6.56% [6400/97600]  [6.6/100.0] [batch_t 0.066 (0.067)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.258 (0.256)]
2025-12-09 21:57:11,590 - Train: 6.61% [6450/97600]  [6.6/100.0] [batch_t 0.066 (0.067)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.274 (0.254)]
2025-12-09 21:57:14,962 - Train: 6.66% [6500/97600]  [6.7/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.267 (0.252)]
2025-12-09 21:57:18,331 - Train: 6.71% [6550/97600]  [6.7/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.232 (0.251)]
2025-12-09 21:57:21,685 - Train: 6.76% [6600/97600]  [6.8/100.0] [batch_t 0.066 (0.067)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.277 (0.257)]
2025-12-09 21:57:25,043 - Train: 6.81% [6650/97600]  [6.8/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.253 (0.252)]
2025-12-09 21:57:28,403 - Train: 6.86% [6700/97600]  [6.9/100.0] [batch_t 0.066 (0.067)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.240 (0.254)]
2025-12-09 21:57:31,802 - Train: 6.92% [6750/97600]  [6.9/100.0] [batch_t 0.075 (0.068)] [data_t 0.001] [optim_t 0.074] [lr 0.000100] [cos 0.230 (0.251)]
2025-12-09 21:57:35,206 - Train: 6.97% [6800/97600]  [7.0/100.0] [batch_t 0.068 (0.068)] [data_t 0.001] [optim_t 0.067] [lr 0.000100] [cos 0.257 (0.254)]
2025-12-09 21:57:37,358 - ==> Total time: 0:09:58	 Eta: 2:12:32 	Logged in 'runs/ViTADTrainer_configs_vitad_vitad_insplad_20251209-214738'
2025-12-09 21:57:56,626 - Train: 7.02% [6850/97600]  [7.0/100.0] [batch_t 0.071 (0.087)] [data_t 0.001] [optim_t 0.070] [lr 0.000100] [cos 0.246 (0.249)]
2025-12-09 21:58:00,089 - Train: 7.07% [6900/97600]  [7.1/100.0] [batch_t 0.068 (0.069)] [data_t 0.001] [optim_t 0.067] [lr 0.000100] [cos 0.239 (0.247)]
2025-12-09 21:58:03,469 - Train: 7.12% [6950/97600]  [7.1/100.0] [batch_t 0.068 (0.067)] [data_t 0.001] [optim_t 0.067] [lr 0.000100] [cos 0.247 (0.251)]
2025-12-09 21:58:06,807 - Train: 7.17% [7000/97600]  [7.2/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.268 (0.248)]
2025-12-09 21:58:10,132 - Train: 7.22% [7050/97600]  [7.2/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.235 (0.246)]
2025-12-09 21:58:13,455 - Train: 7.27% [7100/97600]  [7.3/100.0] [batch_t 0.067 (0.066)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.262 (0.248)]
2025-12-09 21:58:16,785 - Train: 7.33% [7150/97600]  [7.3/100.0] [batch_t 0.065 (0.066)] [data_t 0.001] [optim_t 0.064] [lr 0.000100] [cos 0.251 (0.248)]
2025-12-09 21:58:20,118 - Train: 7.38% [7200/97600]  [7.4/100.0] [batch_t 0.066 (0.067)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.238 (0.245)]
2025-12-09 21:58:23,454 - Train: 7.43% [7250/97600]  [7.4/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.249 (0.248)]
2025-12-09 21:58:26,778 - Train: 7.48% [7300/97600]  [7.5/100.0] [batch_t 0.066 (0.066)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.229 (0.245)]
2025-12-09 21:58:30,136 - Train: 7.53% [7350/97600]  [7.5/100.0] [batch_t 0.066 (0.067)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.256 (0.249)]
2025-12-09 21:58:33,491 - Train: 7.58% [7400/97600]  [7.6/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.243 (0.246)]
2025-12-09 21:58:36,843 - Train: 7.63% [7450/97600]  [7.6/100.0] [batch_t 0.068 (0.067)] [data_t 0.001] [optim_t 0.067] [lr 0.000100] [cos 0.247 (0.246)]
2025-12-09 21:58:40,192 - Train: 7.68% [7500/97600]  [7.7/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.244 (0.246)]
2025-12-09 21:58:43,601 - Train: 7.74% [7550/97600]  [7.7/100.0] [batch_t 0.068 (0.068)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.231 (0.247)]
2025-12-09 21:58:46,976 - Train: 7.79% [7600/97600]  [7.8/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.227 (0.245)]
2025-12-09 21:58:50,371 - Train: 7.84% [7650/97600]  [7.8/100.0] [batch_t 0.069 (0.068)] [data_t 0.001] [optim_t 0.068] [lr 0.000100] [cos 0.251 (0.245)]
2025-12-09 21:58:53,791 - Train: 7.89% [7700/97600]  [7.9/100.0] [batch_t 0.068 (0.068)] [data_t 0.001] [optim_t 0.067] [lr 0.000100] [cos 0.239 (0.242)]
2025-12-09 21:58:57,210 - Train: 7.94% [7750/97600]  [7.9/100.0] [batch_t 0.068 (0.068)] [data_t 0.001] [optim_t 0.067] [lr 0.000100] [cos 0.237 (0.244)]
2025-12-09 21:59:00,615 - Train: 7.99% [7800/97600]  [8.0/100.0] [batch_t 0.071 (0.068)] [data_t 0.001] [optim_t 0.070] [lr 0.000100] [cos 0.246 (0.237)]
2025-12-09 21:59:01,161 - ==> Total time: 0:11:22	 Eta: 2:10:47 	Logged in 'runs/ViTADTrainer_configs_vitad_vitad_insplad_20251209-214738'
2025-12-09 21:59:22,093 - Train: 8.04% [7850/97600]  [8.0/100.0] [batch_t 0.068 (0.074)] [data_t 0.001] [optim_t 0.067] [lr 0.000100] [cos 0.228 (0.241)]
2025-12-09 21:59:25,490 - Train: 8.09% [7900/97600]  [8.1/100.0] [batch_t 0.068 (0.068)] [data_t 0.001] [optim_t 0.067] [lr 0.000100] [cos 0.249 (0.239)]
2025-12-09 21:59:28,830 - Train: 8.15% [7950/97600]  [8.1/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.219 (0.237)]
2025-12-09 21:59:32,162 - Train: 8.20% [8000/97600]  [8.2/100.0] [batch_t 0.066 (0.067)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.235 (0.243)]
2025-12-09 21:59:35,508 - Train: 8.25% [8050/97600]  [8.2/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.231 (0.237)]
2025-12-09 21:59:38,849 - Train: 8.30% [8100/97600]  [8.3/100.0] [batch_t 0.066 (0.067)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.259 (0.242)]
2025-12-09 21:59:42,190 - Train: 8.35% [8150/97600]  [8.4/100.0] [batch_t 0.068 (0.067)] [data_t 0.001] [optim_t 0.067] [lr 0.000100] [cos 0.247 (0.238)]
2025-12-09 21:59:45,532 - Train: 8.40% [8200/97600]  [8.4/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.238 (0.241)]
2025-12-09 21:59:48,877 - Train: 8.45% [8250/97600]  [8.5/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.253 (0.237)]
2025-12-09 21:59:52,245 - Train: 8.50% [8300/97600]  [8.5/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.256 (0.239)]
2025-12-09 21:59:55,621 - Train: 8.56% [8350/97600]  [8.6/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.237 (0.238)]
2025-12-09 21:59:58,994 - Train: 8.61% [8400/97600]  [8.6/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.248 (0.235)]
2025-12-09 22:00:02,337 - Train: 8.66% [8450/97600]  [8.7/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.226 (0.237)]
2025-12-09 22:00:05,678 - Train: 8.71% [8500/97600]  [8.7/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.247 (0.235)]
2025-12-09 22:00:09,053 - Train: 8.76% [8550/97600]  [8.8/100.0] [batch_t 0.067 (0.067)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.219 (0.235)]
2025-12-09 22:00:12,436 - Train: 8.81% [8600/97600]  [8.8/100.0] [batch_t 0.067 (0.068)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.242 (0.236)]
2025-12-09 22:00:15,839 - Train: 8.86% [8650/97600]  [8.9/100.0] [batch_t 0.065 (0.068)] [data_t 0.001] [optim_t 0.064] [lr 0.000100] [cos 0.243 (0.234)]
2025-12-09 22:00:19,254 - Train: 8.91% [8700/97600]  [8.9/100.0] [batch_t 0.070 (0.068)] [data_t 0.001] [optim_t 0.069] [lr 0.000100] [cos 0.233 (0.235)]
2025-12-09 22:00:22,681 - Train: 8.97% [8750/97600]  [9.0/100.0] [batch_t 0.075 (0.068)] [data_t 0.001] [optim_t 0.074] [lr 0.000100] [cos 0.219 (0.234)]
2025-12-09 22:00:24,988 - ==> Total time: 0:12:46	 Eta: 2:09:07 	Logged in 'runs/ViTADTrainer_configs_vitad_vitad_insplad_20251209-214738'
2025-12-09 22:00:45,431 - Train: 9.02% [8800/97600]  [9.0/100.0] [batch_t 0.072 (0.081)] [data_t 0.001] [optim_t 0.071] [lr 0.000100] [cos 0.221 (0.235)]
2025-12-09 22:00:48,933 - Train: 9.07% [8850/97600]  [9.1/100.0] [batch_t 0.069 (0.070)] [data_t 0.001] [optim_t 0.068] [lr 0.000100] [cos 0.234 (0.232)]
2025-12-09 22:00:52,339 - Train: 9.12% [8900/97600]  [9.1/100.0] [batch_t 0.068 (0.068)] [data_t 0.001] [optim_t 0.067] [lr 0.000100] [cos 0.238 (0.235)]
2025-12-09 22:00:55,724 - Train: 9.17% [8950/97600]  [9.2/100.0] [batch_t 0.066 (0.068)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.224 (0.234)]
2025-12-09 22:00:59,124 - Train: 9.22% [9000/97600]  [9.2/100.0] [batch_t 0.067 (0.068)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.230 (0.229)]
2025-12-09 22:01:02,525 - Train: 9.27% [9050/97600]  [9.3/100.0] [batch_t 0.067 (0.068)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.206 (0.231)]
2025-12-09 22:01:05,941 - Train: 9.32% [9100/97600]  [9.3/100.0] [batch_t 0.067 (0.068)] [data_t 0.001] [optim_t 0.065] [lr 0.000100] [cos 0.224 (0.229)]
2025-12-09 22:01:09,363 - Train: 9.38% [9150/97600]  [9.4/100.0] [batch_t 0.068 (0.068)] [data_t 0.001] [optim_t 0.067] [lr 0.000100] [cos 0.238 (0.231)]
2025-12-09 22:01:12,771 - Train: 9.43% [9200/97600]  [9.4/100.0] [batch_t 0.068 (0.068)] [data_t 0.001] [optim_t 0.067] [lr 0.000100] [cos 0.226 (0.230)]
2025-12-09 22:01:16,190 - Train: 9.48% [9250/97600]  [9.5/100.0] [batch_t 0.067 (0.068)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.217 (0.233)]
2025-12-09 22:01:19,608 - Train: 9.53% [9300/97600]  [9.5/100.0] [batch_t 0.068 (0.068)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.225 (0.229)]
2025-12-09 22:01:23,035 - Train: 9.58% [9350/97600]  [9.6/100.0] [batch_t 0.068 (0.068)] [data_t 0.001] [optim_t 0.067] [lr 0.000100] [cos 0.248 (0.228)]
2025-12-09 22:01:26,461 - Train: 9.63% [9400/97600]  [9.6/100.0] [batch_t 0.067 (0.068)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.220 (0.228)]
2025-12-09 22:01:29,884 - Train: 9.68% [9450/97600]  [9.7/100.0] [batch_t 0.074 (0.068)] [data_t 0.001] [optim_t 0.073] [lr 0.000100] [cos 0.238 (0.226)]
2025-12-09 22:01:33,320 - Train: 9.73% [9500/97600]  [9.7/100.0] [batch_t 0.067 (0.069)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.248 (0.231)]
2025-12-09 22:01:36,757 - Train: 9.78% [9550/97600]  [9.8/100.0] [batch_t 0.069 (0.069)] [data_t 0.001] [optim_t 0.068] [lr 0.000100] [cos 0.220 (0.233)]
2025-12-09 22:01:40,173 - Train: 9.84% [9600/97600]  [9.8/100.0] [batch_t 0.068 (0.068)] [data_t 0.001] [optim_t 0.067] [lr 0.000100] [cos 0.232 (0.229)]
2025-12-09 22:01:43,627 - Train: 9.89% [9650/97600]  [9.9/100.0] [batch_t 0.068 (0.069)] [data_t 0.001] [optim_t 0.067] [lr 0.000100] [cos 0.209 (0.230)]
2025-12-09 22:01:47,074 - Train: 9.94% [9700/97600]  [9.9/100.0] [batch_t 0.067 (0.069)] [data_t 0.001] [optim_t 0.066] [lr 0.000100] [cos 0.233 (0.228)]
2025-12-09 22:01:50,495 - Train: 9.99% [9750/97600]  [10.0/100.0] [batch_t 0.068 (0.068)] [data_t 0.001] [optim_t 0.067] [lr 0.000100] [cos 0.233 (0.226)]
2025-12-09 22:02:15,440 - Test: 15.58% [50/321] [batch_t 0.046 (0.059)] [cos 0.185 (0.245)]
2025-12-09 22:02:17,935 - Test: 31.15% [100/321] [batch_t 0.049 (0.055)] [cos 0.251 (0.248)]
2025-12-09 22:02:20,423 - Test: 46.73% [150/321] [batch_t 0.043 (0.053)] [cos 0.232 (0.247)]
2025-12-09 22:02:22,928 - Test: 62.31% [200/321] [batch_t 0.044 (0.052)] [cos 0.268 (0.243)]
